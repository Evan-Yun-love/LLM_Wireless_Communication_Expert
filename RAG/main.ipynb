{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f024414",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docs_preprocess import DocumentProcessor\n",
    "from VecStore import VectorStore\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfca5bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional, Any\n",
    "from langchain_core.language_models.llms import LLM\n",
    "\n",
    "class DeepSeekLLM(LLM):\n",
    "    model: Any\n",
    "    tokenizer: Any\n",
    "    max_new_tokens: int = 512\n",
    "    temperature: float = 0.0           # é»˜è®¤ç»™ RAG ç”¨\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"deepseek_hf\"\n",
    "\n",
    "    def _call(self, prompt: str,\n",
    "              stop: Optional[List[str]] = None,\n",
    "              **kwargs) -> str:\n",
    "        # 1. æŠŠæ™®é€š prompt åŒ…è£…è¿›å®˜æ–¹ chat_template\n",
    "        messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "        input_ids = self.tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            add_generation_prompt=True,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(self.model.device)\n",
    "\n",
    "        # 2. ç”Ÿæˆ\n",
    "        outputs = self.model.generate(\n",
    "            input_ids,\n",
    "            max_new_tokens=kwargs.get(\"max_new_tokens\", self.max_new_tokens),\n",
    "            temperature=kwargs.get(\"temperature\", self.temperature),\n",
    "        )\n",
    "        text = self.tokenizer.decode(\n",
    "            outputs[0][input_ids.shape[1]:],\n",
    "            skip_special_tokens=True,\n",
    "        )\n",
    "\n",
    "        # 3. æ‰‹åŠ¨å¤„ç† stop tokens\n",
    "        if stop:\n",
    "            for s in stop:\n",
    "                if s in text:\n",
    "                    text = text.split(s)[0]\n",
    "\n",
    "        return text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d399e087",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lyus4/anaconda3/envs/rag_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-14 13:04:12,416] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lyus4/anaconda3/envs/rag_env/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "/home/lyus4/anaconda3/envs/rag_env/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00:00,  1.68s/it]\n",
      "We've detected an older driver with an RTX 4000 series GPU. These drivers have issues with P2P. This can affect the multi-gpu inference when using accelerate device_map.Please make sure to update your driver to the latest version which resolves this.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, GenerationConfig\n",
    "\n",
    "model_dir = \"/home/lyus4/yuheng/All_in_LLM/deepseek-llm-7b-chat\"\n",
    "tok   = AutoTokenizer.from_pretrained(model_dir, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_dir,\n",
    "                                             trust_remote_code=True,\n",
    "                                             torch_dtype=\"auto\",\n",
    "                                             device_map=\"auto\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebb709ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3746317/973699687.py:2: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  print(llm(\"ä½ å¥½ï¼Œè¯·è‡ªæˆ‘ä»‹ç»ä¸€ä¸‹ã€‚\"))\n",
      "/home/lyus4/anaconda3/envs/rag_env/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:100001 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä½ å¥½ï¼æˆ‘æ˜¯ä¸€ä¸ªäººå·¥æ™ºèƒ½åŠ©æ‰‹ï¼Œåä¸ºDeepSeek Chatã€‚æˆ‘ç”±ä¸­å›½çš„DeepSeekå›¢é˜Ÿå¼€å‘ï¼Œæ—¨åœ¨å¸®åŠ©ç”¨æˆ·è§£ç­”é—®é¢˜ã€æä¾›ä¿¡æ¯å’Œæ‰§è¡Œå„ç§ä»»åŠ¡ã€‚æˆ‘èƒ½å¤Ÿå¤„ç†å¤šç§ä¸»é¢˜ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºç§‘å­¦ã€æ•°å­¦ã€å†å²ã€æ–‡åŒ–ã€æŠ€æœ¯ç­‰ã€‚å¦‚æœä½ æœ‰ä»»ä½•é—®é¢˜ï¼Œæ¬¢è¿éšæ—¶å‘æˆ‘æé—®ã€‚\n"
     ]
    }
   ],
   "source": [
    "llm = DeepSeekLLM(model=model, tokenizer=tok, max_new_tokens=512, temperature=0.2)\n",
    "print(llm(\"ä½ å¥½ï¼Œè¯·è‡ªæˆ‘ä»‹ç»ä¸€ä¸‹ã€‚\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "613aa40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lyus4/anaconda3/envs/rag_env/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:100001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In wireless communication, RB stands for Resource Block. It is a basic unit of data in the GSM (Global System for Mobile communication) and UMTS (Universal Mobile Telecommunication System) standards. A Resource Block contains information about the data to be transmitted, such as the data itself, error-correction codes, and synchronization information.\n",
      "\n",
      "Resource Blocks are used to encapsulate and transmit data in the air interface of wireless communication systems. They are also used to allocate resources, such as bandwidth and power, to different users or services.\n",
      "\n",
      "In GSM, a Resource Block is typically 128 bytes in size, while in UMTS, it can be up to 64 KB. The size of a Resource Block can vary depending on the specific requirements of the communication system and the type of data being transmitted.\n"
     ]
    }
   ],
   "source": [
    "print(llm(\"In Wireless communication, what is RB\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f0e584",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bae25f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è·¯å¾„é…ç½®\n",
    "MODEL_PATH =  \"/home/lyus4/yuheng/All_in_LLM/all-MiniLM-L6-v2\"\n",
    "INDEX_PATH = Path(\"../vector_store/faiss_ivfflat_100\")  # æ— éœ€åŠ  .index åç¼€\n",
    "VECTORS_PATH = Path(\"../index/vectors.npy\")\n",
    "DOC_JSON_PATH = Path(\"output_chunks.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88c2281f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] åˆå§‹åŒ– VectorStore -> ../vector_store/faiss_ivfflat_100\n",
      "[INFO] ç´¢å¼•åŠ è½½æˆåŠŸ: ../vector_store/faiss_ivfflat_100\n",
      "[INFO] ç±»å‹: IndexIVFFlat, ç»´åº¦: 384, æ•°é‡: 18343\n",
      "[INFO] åŠ è½½æ–‡æ¡£ 18343 æ¡\n",
      "\n",
      "[INFO] VectorStore çŠ¶æ€æè¿°ï¼š\n",
      "- æ–‡æ¡£æ•°: 18343\n",
      "- å‘é‡æ•°: 0\n",
      "- ç´¢å¼•ç±»å‹: IndexIVFFlat\n",
      "- å‘é‡ç»´åº¦: 384\n",
      "- å‘é‡æ€»æ•°: 18343\n"
     ]
    }
   ],
   "source": [
    "vs = VectorStore(model_path=MODEL_PATH, db_path=INDEX_PATH)\n",
    "vs.load_documents_and_metadata(json_path=DOC_JSON_PATH)\n",
    "vs.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9593c900",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lyus4/yuheng/All_in_LLM/LLM_wireless_communication_expert/RAG/VecStore.py:39: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  self.model = HuggingFaceEmbeddings(\n",
      "No sentence-transformers model found with name /home/lyus4/yuheng/All_in_LLM/all-MiniLM-L6-v2. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] åµŒå…¥æ¨¡å‹å·²åŠ è½½\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results = vs.search(\"what is OFDMA?\", k=5, score_mode=\"reciprocal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "628031df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Orthogonal frequency division multiple access (OFDMA), which is the multi-user\\nversion of OFDM that was discussed in Section 9.12. In OFDMA multiple access is\\naccomplished through the assignment of subchannels (subcarriers) to individual users.',\n",
       "  0.6585590018011712,\n",
       "  {'document': '../documents/Digital-Communication-Systems.pdf',\n",
       "   'page': 587,\n",
       "   'chunk_idx': 5}),\n",
       " ('Chapter\\nSignaling over Fading Channels\\nNaturally, OFDMA inherits the distinctive features of OFDM. In particular, OFDMA\\nis well suited for high data-rate transmissions over delay-dispersive channels, realized\\nby exploiting the principle of divide and conquer. Accordingly, OFDMA is\\ncomputationally efficient in using the FFT algorithm. Moreover, OFDMA lends itself\\nto the combined use of MIMO, hence the ability to improve spectral efficiency and\\ntake advantage of channel flexibility.\\nCode-division multiple access (CDMA), which distinguishes itself by exploiting the\\nunderlying principle of spread spectrum signals, discussed in Section 9.13. To be\\nspecific, through the combined process of spectrum spreading in the transmitter and',\n",
       "  0.5332675930110392,\n",
       "  {'document': '../documents/Digital-Communication-Systems.pdf',\n",
       "   'page': 588,\n",
       "   'chunk_idx': 0}),\n",
       " ('the two. This important result assumes that the receiver has knowledge of the channel\\nstate. The spectral efficiency of the MIMO system can be further enhanced by including a\\nfeedback channel from the transmitter to the receiver, whereby the channel state is also\\nmade available to the transmitter and with it the transmitter is enabled to exercise control\\nover the transmitted signal.\\nMultiple Access Considerations\\nAn issue of paramount practical importance in wireless communications is that of multiple\\naccess to the wireless channel, in the context of which the following two approaches are\\nconsidered to be the dominant ones:\\nOrthogonal frequency division multiple access (OFDMA), which is the multi-user\\nversion of OFDM that was discussed in Section 9.12. In OFDMA multiple access is',\n",
       "  0.5080075333243746,\n",
       "  {'document': '../documents/Digital-Communication-Systems.pdf',\n",
       "   'page': 587,\n",
       "   'chunk_idx': 4}),\n",
       " ('The base class for OFDMA schedulers is NrMacSchedulerOfdma. In the downlink, such class and its subclasses\\nperform OFDMA scheduling, while in the uplink they leverage some of the subclasses of NrMacSchedulerTdma\\nclass that implements TDMA scheduling.\\nThe OFDMA scheduling in the downlink is composed of the two scheduling levels: 1) the scheduling of the symbols\\nper beam (time-domain level), where scheduler selects a number of consecutive OFDM symbols in a slot to assign to a\\nspecific beam, and 2) the scheduling of RBGs per UE in a beam, where the scheduler determines the allocation of RBGs\\nfor the OFDM symbols of the corresponding beam (frequency-domain level). The scheduling of the symbols per beam',\n",
       "  0.4974497467181104,\n",
       "  {'document': '../documents/nrmodule.pdf', 'page': 35, 'chunk_idx': 2}),\n",
       " ('agate through the channel and hence go through narrowband parallel channels. This\\ninterpretation justifies the name of OFDM for this communication scheme. Finally,\\nwe remark that DFT and IDFT can be very eciently implemented (and denoted as\\nFFT and IFFT, respectively) whenever Nc is a power of 2.\\nOFDM Block Length\\nThe OFDM scheme converts communication over a multipath channel into communi-\\ncation over simpler parallel narrowband channels. However, this simplicity is achieved\\nat a cost of underutilizing two resources, resulting in a loss of performance. First, the\\ncyclic prefix occupies an amount of time which cannot be used to communicate data.',\n",
       "  0.4973045651123567,\n",
       "  {'document': '../documents/Fundamentals of Wireless Communication.pdf',\n",
       "   'page': 119,\n",
       "   'chunk_idx': 3})]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbccc6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<Role>\n",
      "You are a 5G wireless communication expert.\n",
      "\n",
      "<Goal>\n",
      "Answer the question using the information in the context below.\n",
      "If the context is insufficient, reply exactly: **\"I don't know\"**.\n",
      "\n",
      "<Context>\n",
      "[Document: ../documents/3GPP_38/38214-i60.docx, Page: 1]\n",
      "(score=0.495) to the UE reported threshold beamSwitchTiming when the reported value is one of the values {14,28,48} and when enableBeamSwitchTiming is not provided or the NZP-CSI-RS-ResourceSet is configured with the higher layer parameter trs-Info , aperiodic CSI-RS in a NZP-CSI-RS-ResourceSet configured with the higher layer parameter repetition set to 'off' or configured without the higher layer parameters repetition and trs-Info scheduled with offset larger than or equal to 48 when the UE provides beamSwitchTiming-r16 and enableBeamSwitchTiming is provided, aperiodic CSI-RS in a NZP-CSI-RS-ResourceSet configured with the higher layer parameter repetition set to 'on' scheduled with offset larger than or equal to the UE reported threshold beamSwitchTiming-r16 and enableBeamSwitchTiming is provided;\n",
      "\n",
      "---\n",
      "\n",
      "[Document: ../documents/3GPP_38/38331-i51.docx, Page: 1]\n",
      "(score=0.503) (AGC) and beam management, if configured. For each serving cell other than the SpCell or PUCCH SCell, the network may configure one BWP as a dormant BWP. Earth-fixed cell: An NTN cell fixed with respect to a certain geographic area on Earth. It can be provisioned by beam(s) continuously covering the same geographical area (e.g., the case of GSO satellites). Earth-moving cell: An NTN cell moving on the ground. It can be provisioned by beam(s) whose coverage area slides over the Earth's surface (e.g., the case of NGSO satellites generating fixed or non-steerable beams). eRedCap UE: A UE with enhanced reduced capabilities as specified in clause 4.2.22.1 in TS 38.306 [26]. Field: The individual contents of an information element are referred to as fields. FLOOR: Mathematical function used to\n",
      "\n",
      "---\n",
      "\n",
      "[Document: ../documents/Fundamentals of Wireless Communication.pdf, Page: 549]\n",
      "(score=0.502) yk[m] = hkxi[m] + wk[m].\n",
      "(10.77)\n",
      "If there are enough users in the system, for every beam i some user will be nearly in\n",
      "beamforming configuration with respect to it (and simultaneously nearly orthogonal to\n",
      "the other beams). Thus we have nt data streams being transmitted simultaneously in\n",
      "orthogonal spatial directions and the full spatial degrees of freedom are being utilized.\n",
      "The limited feedback from the users allows opportunistic scheduling of the user trans-\n",
      "missions in the appropriate beams at the appropriate time slots. To achieve close to\n",
      "the beamforming (and corresponding nulling to all the other beams) performance re-\n",
      "quires a user population that is larger than in the scenario of Section 6.7.3. In general,\n",
      "\n",
      "<Question>\n",
      "What is beam management?\n",
      "\n",
      "<Instructions>\n",
      "1. Explain simply and clearly, as if to a non-expert.  \n",
      "2. Use the following **answer format strictly**:  \n",
      "   - Start with a 1-2 sentence summary.  \n",
      "   - Then, list the explanation in **numbered bullet points** (1., 2., 3., etc.).  \n",
      "3. Give the reference.\n",
      "4. Conform to 3GPP protocol.\n",
      "\n",
      "<Answer>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from utils import format_context_grouped, expand_acronyms\n",
    "# å®šä¹‰ Prompt æ¨¡æ¿\n",
    "\n",
    "template_test = \"\"\"\n",
    "<Role>\n",
    "You are a 5G wireless communication expert.\n",
    "\n",
    "<Goal>\n",
    "Answer the question using the information in the context below.\n",
    "If the context is insufficient, reply exactly: **\"I don't know\"**.\n",
    "\n",
    "<Context>\n",
    "{context}\n",
    "\n",
    "<Question>\n",
    "{question}\n",
    "\n",
    "<Instructions>\n",
    "1. Explain simply and clearly, as if to a non-expert.  \n",
    "2. Use the following **answer format strictly**:  \n",
    "   - Start with a 1-2 sentence summary.  \n",
    "   - Then, list the explanation in **numbered bullet points** (1., 2., 3., etc.).  \n",
    "3. Give the reference.\n",
    "4. Conform to 3GPP protocol.\n",
    "\n",
    "<Answer>\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=template_test\n",
    ")\n",
    "\n",
    "# æ‰§è¡Œæ£€ç´¢\n",
    "question = \"What is beam management?\"\n",
    "question = expand_acronyms(question)\n",
    "\n",
    "top_k_results = vs.search(question, k=3, score_mode=\"reciprocal\")\n",
    "context = format_context_grouped(top_k_results, with_metadata=True, with_score=True)\n",
    "\n",
    "# æ„é€  Prompt è¾“å…¥\n",
    "prompt_input = prompt.format(context=context, question=question)\n",
    "\n",
    "# è¾“å‡º promptï¼ˆå¯ä¼ å…¥ LLMï¼‰\n",
    "print(prompt_input)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91c9e827",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lyus4/anaconda3/envs/rag_env/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:100001 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(prompt_input)\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6dbda788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beam management refers to the process of controlling and optimizing the use of beams in a 5G wireless communication system. This includes tasks such as beamforming, beam switching, and beam allocation. Beamforming is the process of directing radio signals towards a specific user or group of users by using multiple antennas at the transmitter and receiver. Beam switching is the process of switching between different beams to improve signal quality or to avoid interference from other beams. Beam allocation is the process of assigning users to specific beams based on their location and the available beams in the system. Beam management is an important aspect of 5G wireless communication as it helps to improve the efficiency and performance of the system by optimizing the use of radio resources.\n",
      "\n",
      "*Beam management is a process that involves controlling and optimizing the use of beams in a 5G wireless communication system.*\n",
      "\n",
      "*Beamforming is the process of directing radio signals towards a specific user or group of users by using multiple antennas at the transmitter and receiver.*\n",
      "\n",
      "*Beam switching is the process of switching between different beams to improve signal quality or to avoid interference from other beams.*\n",
      "\n",
      "*Beam allocation is the process of assigning users to specific beams based on their location and the available beams in the system.*\n",
      "\n",
      "*Beam management is an important aspect of 5G wireless communication as it helps to improve the efficiency and performance of the system by optimizing the use of radio resources.*\n",
      "\n",
      "Reference:\n",
      "\n",
      "* [Document: Fundamentals of Wireless Communication.pdf](../documents/Fundamentals of Wireless Communication.pdf)\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3c55bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lyus4/anaconda3/envs/rag_env/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:100001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beam management is a key technology in 5G wireless communications that allows for the efficient use of radio frequency (RF) resources and improved network performance. It involves the use of multiple antennas at the base station and the mobile device to create a beam of radio waves that is directed towards the device, rather than broadcasting in all directions. This allows for a more focused and efficient use of RF resources, which can lead to improved data rates, reduced latency, and increased capacity in the network. Beam management can also be used to improve the signal quality for devices that are located in areas with poor signal strength, by directing the beam towards the device and reducing interference from other sources.\n"
     ]
    }
   ],
   "source": [
    "response_raw = llm.invoke(\"In 5G wireless communications, What is beam management?\")\n",
    "print(response_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1b80284a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lyus4/anaconda3/envs/rag_env/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:100001 for open-end generation.\n",
      "/home/lyus4/anaconda3/envs/rag_env/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:100001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====== å¯¹è¯å›åˆ ======\n",
      "[ğŸ§‘â€ğŸ’¬] What is beam management?\n",
      "[ğŸ¤–] Beam management refers to the process of controlling and optimizing the use of beams in a 5G wireless communication\n",
      "system. This includes tasks such as configuring and managing beam configurations, adjusting beam patterns, and managing\n",
      "beam switching between different cells or serving areas. The goal of beam management is to improve the overall\n",
      "performance and efficiency of the communication system by ensuring that signals are transmitted and received as\n",
      "effectively as possible.  <Reference> The concept of beam management is not directly mentioned in the provided context\n",
      "documents. However, it is related to the overall management of beams in a 5G system, which is discussed in more detail\n",
      "in the \"Fundamentals of Wireless Communication\" document.\n",
      "\n",
      "====== å¯¹è¯å›åˆ ======\n",
      "[ğŸ§‘â€ğŸ’¬] And why is it important?\n",
      "[ğŸ¤–] AI: Beam management is important because it helps to optimize the use of beams in a 5G wireless communication system,\n",
      "which can improve the overall performance and efficiency of the communication system. By controlling and adjusting beam\n",
      "patterns and switching between different beams, beam management can help to ensure that signals are transmitted and\n",
      "received as effectively as possible, leading to better quality of service and increased capacity. Additionally, beam\n",
      "management can help to reduce interference and improve the overall coverage of the communication system.\n",
      "\n",
      "====== å†å²è®°å½• ======\n",
      "\n",
      "ğŸ§‘â€ğŸ’¬ Q1: What is beam management?\n",
      "ğŸ¤– A1: Beam management refers to the process of controlling and optimizing the use of beams in a 5G wireless communication\n",
      "system. This includes tasks such as configuring and managing beam configurations, adjusting beam patterns, and managing\n",
      "beam switching between different cells or serving areas. The goal of beam management is to improve the overall\n",
      "performance and efficiency of the communication system by ensuring that signals are transmitted and received as\n",
      "effectively as possible.  <Reference> The concept of beam management is not directly mentioned in the provided context\n",
      "documents. However, it is related to the overall management of beams in a 5G system, which is discussed in more detail\n",
      "in the \"Fundamentals of Wireless Communication\" document.\n",
      "\n",
      "ğŸ§‘â€ğŸ’¬ Q2: And why is it important?\n",
      "ğŸ¤– A2: AI: Beam management is important because it helps to optimize the use of beams in a 5G wireless communication system,\n",
      "which can improve the overall performance and efficiency of the communication system. By controlling and adjusting beam\n",
      "patterns and switching between different beams, beam management can help to ensure that signals are transmitted and\n",
      "received as effectively as possible, leading to better quality of service and increased capacity. Additionally, beam\n",
      "management can help to reduce interference and improve the overall coverage of the communication system.\n"
     ]
    }
   ],
   "source": [
    "# â”€â”€ ä¾èµ– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import (\n",
    "    Runnable, RunnableLambda, RunnableWithMessageHistory\n",
    ")\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "import textwrap\n",
    "from utils import format_context_grouped, expand_acronyms\n",
    "\n",
    "# ä½ çš„llmå’Œvsåˆå§‹åŒ–ç•¥\n",
    "\n",
    "# â”€â”€ 1. Prompt æ¨¡æ¿ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "template_test = \"\"\"\n",
    "<Role>\n",
    "You are a 5G wireless communication expert.\n",
    "\n",
    "<Goal>\n",
    "Answer the question using the information in the context below.\n",
    "If the context is insufficient, reply exactly: **\"I don't know\"**.\n",
    "\n",
    "<Context>\n",
    "{context}\n",
    "\n",
    "<Question>\n",
    "{question}\n",
    "\n",
    "<Instructions>\n",
    "1. Explain simply and clearly, as if to a non-expert.  \n",
    "2. Give the reference.\n",
    "\n",
    "<Answer>\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template_test),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),  # å¤šè½®å†å²æ’å…¥\n",
    "    (\"user\", \"<Question>\\n{question}\")\n",
    "])\n",
    "\n",
    "# â”€â”€ 2. æ„é€ ä¸Šä¸‹æ–‡ï¼ˆæ”¯æŒå†å²é—®å¥åˆå¹¶ï¼‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def build_inputs(inputs: dict):\n",
    "    question = inputs[\"input\"]\n",
    "    history_msgs = inputs.get(\"history\", [])\n",
    "\n",
    "    # åˆå¹¶å†å²ä¸­æ‰€æœ‰ HUMAN æ¶ˆæ¯ä½œä¸ºæ£€ç´¢ query\n",
    "    history_text = \"\\n\".join([msg.content for msg in history_msgs if getattr(msg, \"type\", getattr(msg, \"role\", \"\")).lower() in [\"human\", \"user\"]])\n",
    "    combined_query = f\"{history_text}\\n{question}\" if history_text else question\n",
    "    q_exp = expand_acronyms(combined_query)\n",
    "\n",
    "    # æ£€ç´¢ä¸Šä¸‹æ–‡\n",
    "    top_k_results = vs.search(q_exp, k=3, score_mode=\"reciprocal\")\n",
    "    ctx = format_context_grouped(top_k_results, with_metadata=True, with_score=True)\n",
    "\n",
    "    # ä¼ é€’promptæ¨¡æ¿è¦æ±‚çš„å˜é‡å\n",
    "    output = dict(inputs)\n",
    "    output.update({\n",
    "        \"context\": ctx,\n",
    "        \"question\": question\n",
    "    })\n",
    "    return output\n",
    "\n",
    "context_retriever = RunnableLambda(build_inputs)\n",
    "\n",
    "# â”€â”€ 3. æ„å»ºå®Œæ•´å¯¹è¯é“¾ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "base_chain: Runnable = (\n",
    "    context_retriever |\n",
    "    chat_prompt |\n",
    "    llm |\n",
    "    StrOutputParser()\n",
    ")\n",
    "\n",
    "# â”€â”€ 4. å†å²å·¥å‚ï¼ˆæ”¯æŒç¼“å­˜ï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "history_store = {}\n",
    "\n",
    "def history_factory(session_id: str):\n",
    "    if session_id not in history_store:\n",
    "        history_store[session_id] = InMemoryChatMessageHistory()\n",
    "    return history_store[session_id]\n",
    "\n",
    "# â”€â”€ 5. æ„å»ºå¸¦å†å²æ”¯æŒçš„ chatbot â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "chatbot = RunnableWithMessageHistory(\n",
    "    base_chain,\n",
    "    history_factory,\n",
    "    input_messages_key=\"input\",      # æœ¬è½®é—®é¢˜å­—æ®µ\n",
    "    history_messages_key=\"history\"   # å¤šè½®æ¶ˆæ¯å­—æ®µ\n",
    ")\n",
    "\n",
    "MAX_HISTORY_MESSAGES = 6\n",
    "\n",
    "def trim_history(session_id: str, max_messages=MAX_HISTORY_MESSAGES):\n",
    "    history = history_factory(session_id).messages\n",
    "    if len(history) > max_messages:\n",
    "        history[:] = history[-max_messages:]\n",
    "\n",
    "# â”€â”€ 6. ç¤ºä¾‹è°ƒç”¨ï¼ˆæ”¯æŒå¤šè½®ï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "session_id = \"user_42\"\n",
    "\n",
    "def wrap_text(text, width=120):\n",
    "    return textwrap.fill(text, width=width)\n",
    "\n",
    "def print_qa_round(question: str, response: str):\n",
    "    print(\"\\n====== å¯¹è¯å›åˆ ======\")\n",
    "    print(f\"[ğŸ§‘â€ğŸ’¬] {wrap_text(question)}\")\n",
    "    print(f\"[ğŸ¤–] {wrap_text(response)}\")\n",
    "\n",
    "def print_chat_history(session_id: str):\n",
    "    print(\"\\n====== å†å²è®°å½• ======\")\n",
    "    history = history_factory(session_id).messages\n",
    "    for i in range(0, len(history), 2):\n",
    "        q = wrap_text(history[i].content) if i < len(history) else \"\"\n",
    "        a = wrap_text(history[i+1].content) if i+1 < len(history) else \"\"\n",
    "        print(f\"\\nğŸ§‘â€ğŸ’¬ Q{i//2 + 1}: {q}\")\n",
    "        print(f\"ğŸ¤– A{i//2 + 1}: {a}\")\n",
    "\n",
    "# ç¬¬ 1 è½®\n",
    "question1 = \"What is beam management?\"\n",
    "response1 = chatbot.invoke(\n",
    "    {\"input\": question1},\n",
    "    config={\"configurable\": {\"session_id\": session_id}}\n",
    ")\n",
    "trim_history(session_id)\n",
    "print_qa_round(question1, response1)\n",
    "\n",
    "# ç¬¬ 2 è½®\n",
    "question2 = \"And why is it important?\"\n",
    "response2 = chatbot.invoke(\n",
    "    {\"input\": question2},\n",
    "    config={\"configurable\": {\"session_id\": session_id}}\n",
    ")\n",
    "trim_history(session_id)\n",
    "print_qa_round(question2, response2)\n",
    "\n",
    "# æ‰“å°å†å²é—®ç­”\n",
    "print_chat_history(session_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2413bcef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
