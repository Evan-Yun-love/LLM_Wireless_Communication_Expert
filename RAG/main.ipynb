{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f024414",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docs_preprocess import DocumentProcessor\n",
    "from VecStore import VectorStore\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfca5bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lyus4/anaconda3/envs/rag_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Optional, Any\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "import torch\n",
    "from langchain_core.language_models.llms import LLM\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "class DeepSeekLLM(LLM):\n",
    "    model: Any\n",
    "    tokenizer: Any\n",
    "\n",
    "    # ==== é€šç”¨ç”Ÿæˆè¶…å‚ ====\n",
    "    max_new_tokens: int = 512\n",
    "    temperature: float  = 0.7\n",
    "    do_sample: bool     = True\n",
    "    top_p: float        = 0.9\n",
    "    top_k: int          = 50\n",
    "\n",
    "    # è®© IDE èƒ½è¡¥å…¨ï¼›LangChain ä¼šç”¨\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"deepseek_hf\"\n",
    "\n",
    "    # --- è‡ªåŠ¨è¡¥ pad_token_idï¼Œé¿å…è­¦å‘Š ---\n",
    "    def __post_init__(self):\n",
    "        if self.tokenizer.pad_token_id is None:\n",
    "            self.tokenizer.pad_token_id = self.tokenizer.eos_token_id\n",
    "        if getattr(self.model.config, \"pad_token_id\", None) is None:\n",
    "            self.model.config.pad_token_id = self.tokenizer.pad_token_id\n",
    "\n",
    "    # -------------------------------------------------------------\n",
    "    def _call(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        stop: Optional[List[str]] = None,\n",
    "        **kwargs,\n",
    "    ) -> str:\n",
    "\n",
    "        # 1) prompt â†’ input_ids\n",
    "        messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "        input_ids = self.tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            add_generation_prompt=True,\n",
    "            return_tensors=\"pt\",\n",
    "        ).to(self.model.device)\n",
    "\n",
    "        attention_mask = (input_ids != self.tokenizer.pad_token_id).long()\n",
    "\n",
    "        # 2) ç»„è£…è¶…å‚ï¼ˆkwargs > å®ä¾‹å­—æ®µï¼‰\n",
    "        gen_kwargs = dict(\n",
    "            max_new_tokens = kwargs.get(\"max_new_tokens\", self.max_new_tokens),\n",
    "            do_sample      = kwargs.get(\"do_sample\",      self.do_sample),\n",
    "            temperature    = kwargs.get(\"temperature\",    self.temperature),\n",
    "            top_p          = kwargs.get(\"top_p\",          self.top_p),\n",
    "            top_k          = kwargs.get(\"top_k\",          self.top_k),\n",
    "            pad_token_id   = self.tokenizer.pad_token_id,\n",
    "            attention_mask = attention_mask,\n",
    "        )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model.generate(input_ids, **gen_kwargs)\n",
    "\n",
    "        text = self.tokenizer.decode(\n",
    "            outputs[0][input_ids.shape[1]:],\n",
    "            skip_special_tokens=True,\n",
    "        )\n",
    "\n",
    "        # 3) stop words æ‰‹åŠ¨æˆªæ–­\n",
    "        if stop:\n",
    "            for s in stop:\n",
    "                if s in text:\n",
    "                    text = text.split(s)[0]\n",
    "\n",
    "        return text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d399e087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-14 18:07:18,421] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lyus4/anaconda3/envs/rag_env/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "/home/lyus4/anaconda3/envs/rag_env/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.44s/it]\n",
      "We've detected an older driver with an RTX 4000 series GPU. These drivers have issues with P2P. This can affect the multi-gpu inference when using accelerate device_map.Please make sure to update your driver to the latest version which resolves this.\n"
     ]
    }
   ],
   "source": [
    "model_dir = \"/home/lyus4/yuheng/All_in_LLM/deepseek-llm-7b-chat\"\n",
    "tok   = AutoTokenizer.from_pretrained(model_dir, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_dir,\n",
    "                                             trust_remote_code=True,\n",
    "                                             torch_dtype=\"auto\",\n",
    "                                             device_map=\"auto\",\n",
    "                                            )\n",
    "\n",
    "llm = DeepSeekLLM(model=model, tokenizer=tok, max_new_tokens=512, temperature=0.2, do_sample = True, top_p = 0.95, top_k = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48798d37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bae25f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è·¯å¾„é…ç½®\n",
    "MODEL_PATH =  \"/home/lyus4/yuheng/All_in_LLM/all-MiniLM-L6-v2\"\n",
    "INDEX_PATH = Path(\"../vector_store/faiss_ivfflat_100\")  # æ— éœ€åŠ  .index åç¼€\n",
    "VECTORS_PATH = Path(\"../index/vectors.npy\")\n",
    "DOC_JSON_PATH = Path(\"output_chunks.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88c2281f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] åˆå§‹åŒ– VectorStore -> ../vector_store/faiss_ivfflat_100\n",
      "[INFO] ç´¢å¼•åŠ è½½æˆåŠŸ: ../vector_store/faiss_ivfflat_100\n",
      "[INFO] ç±»å‹: IndexIVFFlat, ç»´åº¦: 384, æ•°é‡: 18343\n",
      "[INFO] åŠ è½½æ–‡æ¡£ 18343 æ¡\n",
      "\n",
      "[INFO] VectorStore çŠ¶æ€æè¿°ï¼š\n",
      "- æ–‡æ¡£æ•°: 18343\n",
      "- å‘é‡æ•°: 0\n",
      "- ç´¢å¼•ç±»å‹: IndexIVFFlat\n",
      "- å‘é‡ç»´åº¦: 384\n",
      "- å‘é‡æ€»æ•°: 18343\n"
     ]
    }
   ],
   "source": [
    "vs = VectorStore(model_path=MODEL_PATH, db_path=INDEX_PATH)\n",
    "vs.load_documents_and_metadata(json_path=DOC_JSON_PATH)\n",
    "vs.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b80284a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ ä¾èµ– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import (\n",
    "    Runnable, RunnableLambda, RunnableWithMessageHistory\n",
    ")\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "import textwrap\n",
    "from utils import format_context_grouped, expand_acronyms\n",
    "\n",
    "# ä¸€ä¸ªæç®€æ‘˜è¦ Prompt\n",
    "summary_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \n",
    "     \"You are a note-taking assistant.\\n\"\n",
    "     \"Rewrite the following conversation so far into 1-2 concise sentences, \"\n",
    "     \"focusing only on facts or user preferences we should remember.\\n\\n\"\n",
    "     \"{conversation}\")\n",
    "])\n",
    "summary_chain = summary_prompt | llm | StrOutputParser()\n",
    "\n",
    "history_store      = {}   # åŸæœ‰\n",
    "summary_store      = {}   # æ–°å¢ï¼šsession_id -> str\n",
    "\n",
    "MAX_HISTORY_EVENTS = 4        # çª—å£å†…åŸå§‹æ¶ˆæ¯ <= 6 æ¡\n",
    "MAX_TURNS_PER_SESSION = 4    # æ–¹æ¡ˆ Aï¼š30 ä¸ª Q/A åé‡ç½®\n",
    "MAX_SUMMARY_CHARS = 100       # æ–¹æ¡ˆ Bï¼šæ‘˜è¦é•¿åº¦é˜ˆå€¼ï¼ˆå­—ç¬¦ï¼‰\n",
    "RESET_PRESERVE_SUMMARY  = False\n",
    "\n",
    "# ä½ çš„llmå’Œvsåˆå§‹åŒ–ç•¥\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3224af55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def history_factory(session_id: str) -> InMemoryChatMessageHistory:\n",
    "    if session_id not in history_store:\n",
    "        history_store[session_id] = InMemoryChatMessageHistory()\n",
    "    return history_store[session_id]\n",
    "\n",
    "# ---------- A. æ¯è½®éƒ½æ›´æ–°é•¿æœŸæ‘˜è¦ ---------------------------------  # â† CHANGED\n",
    "def update_summary(session_id: str, new_messages):\n",
    "    \"\"\"æŠŠæ—§æ‘˜è¦ + æœ¬è½®å†…å®¹ â†’ æ–°æ‘˜è¦ï¼›è‹¥è¿‡é•¿å†é‡å‹ç¼©ã€‚\"\"\"\n",
    "    prev = summary_store.get(session_id, \"\")\n",
    "    delta = \"\\n\".join(m.content for m in new_messages).strip()\n",
    "    conversation = f\"{prev}\\n{delta}\".strip() if prev else delta\n",
    "\n",
    "    try:\n",
    "        summary = summary_chain.invoke({\"conversation\": conversation})\n",
    "    except Exception:\n",
    "        return  # å¤±è´¥ä¿æŒæ—§æ‘˜è¦\n",
    "\n",
    "    # ---- è‹¥æ‘˜è¦å¤ªé•¿ï¼Œå†å‹æˆä¸€å¥è¯ ----\n",
    "    if len(summary) > MAX_SUMMARY_CHARS:\n",
    "        try:\n",
    "            summary = summary_chain.invoke({\n",
    "                \"conversation\": summary,\n",
    "                # ä¹Ÿå¯ä»¥è®© prompt å˜æˆâ€œå†æµ“ç¼©æˆä¸€å¥â€\n",
    "            })\n",
    "        except Exception:\n",
    "            pass    # å…œåº•ä»ç”¨è¶…é•¿ç‰ˆæœ¬\n",
    "\n",
    "    summary_store[session_id] = summary\n",
    "\n",
    "\n",
    "# ---------- B. ä»…è£å‰ªçŸ­æœŸçª—å£ ------------------------------------  # â† CHANGED\n",
    "def _msg_role(msg) -> str:\n",
    "    \"\"\"return 'human' / 'ai' / 'system'... å…¼å®¹ .role å’Œ .type\"\"\"\n",
    "    return getattr(msg, \"role\", getattr(msg, \"type\", \"\")).lower()\n",
    "\n",
    "turn_counter: dict[str, int] = {}\n",
    "\n",
    "def trim_messages(session_id: str):\n",
    "    hist_obj = history_factory(session_id)\n",
    "    msgs     = hist_obj.messages\n",
    "\n",
    "    # ------- 1. å›åˆè®¡æ•°ï¼ˆåœ¨è£å‰ªä¹‹å‰ï¼‰ -------\n",
    "    turns = turn_counter.get(session_id, 0)\n",
    "    # å½“ä¸”ä»…å½“â€œç”¨æˆ· + AIâ€å„åˆ°ä½æ‰ç®—ä¸€è½®\n",
    "    if len(msgs) >= 2 and _msg_role(msgs[-1]) in (\"ai\", \"assistant\"):\n",
    "        turns += 1\n",
    "        turn_counter[session_id] = turns\n",
    "\n",
    "    if turns >= MAX_TURNS_PER_SESSION:\n",
    "        print(f\"[INFO] session {session_id} reaches {turns} turns, resettingâ€¦\")\n",
    "        history_store[session_id] = InMemoryChatMessageHistory()\n",
    "        turn_counter[session_id]  = 0\n",
    "        if not RESET_PRESERVE_SUMMARY:\n",
    "            summary_store[session_id] = \"\"\n",
    "        return                      # ç›´æ¥è¿”å›ï¼Œä¸‹é¢è£å‰ªå·²æ— æ„ä¹‰\n",
    "\n",
    "    # ------- 2. çª—å£è£å‰ªï¼ˆä¿è¯æˆå¯¹ï¼‰ -------\n",
    "    if len(msgs) > MAX_HISTORY_EVENTS:\n",
    "        start = len(msgs) - MAX_HISTORY_EVENTS\n",
    "        if _msg_role(msgs[start]) not in (\"human\", \"user\"):\n",
    "            start += 1\n",
    "        msgs[:] = msgs[start:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "930c3a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_test = \"\"\"\n",
    "<Role>\n",
    "You are a 5G wireless communication expert.\n",
    "\n",
    "<Goal>\n",
    "Answer the question using the information in the context below.\n",
    "If the context is insufficient, reply exactly: **\"I don't know\"**.\n",
    "\n",
    "<Memory>\n",
    "{summary}\n",
    "\n",
    "<Context>\n",
    "{context}\n",
    "\n",
    "<Question>\n",
    "{question}\n",
    "\n",
    "<Instructions>\n",
    "1. Explain simply and clearly, as if to a non-expert.  \n",
    "2. Give the reference.\n",
    "\n",
    "<Answer>\n",
    "\"\"\"\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template_test),\n",
    "    MessagesPlaceholder(\"history\"),\n",
    "    (\"user\", \"<Question>\\n{question}\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17b26620",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_inputs(inputs: dict):\n",
    "    question       = inputs[\"input\"]\n",
    "    session_id     = inputs[\"session_id\"]     # ğŸ‘‰ â‘  æŠŠ session_id ä¸€å¹¶ä¼ è¿›æ¥\n",
    "    history_msgs   = inputs.get(\"history\", [])\n",
    "\n",
    "    # â€”â€” A. æ£€ç´¢ queryï¼šå†å² Human + å½“å‰é—®é¢˜ â€”â€”\n",
    "    hist_text = \"\\n\".join(\n",
    "        m.content for m in history_msgs        # æœ€è¿‘å‡ æ¡\n",
    "        if (getattr(m, \"type\", getattr(m, \"role\", \"\")).lower()\n",
    "            in (\"human\", \"user\"))\n",
    "    )\n",
    "    combined       = f\"{hist_text}\\n{question}\" if hist_text else question\n",
    "    expanded_query = expand_acronyms(combined)\n",
    "\n",
    "    # â€”â€” B. VS æ£€ç´¢ä¸Šä¸‹æ–‡ â€”â€”\n",
    "    top_k_results  = vs.search(expanded_query, k=3, score_mode=\"reciprocal\")\n",
    "    ctx            = format_context_grouped(top_k_results,\n",
    "                                            with_metadata=True,\n",
    "                                            with_score=True)\n",
    "\n",
    "    # â€”â€” C. æ³¨å…¥æ‘˜è¦ â€”â€” \n",
    "    summary        = summary_store.get(session_id, \"\")   # â† æ—§è®°å¿†\n",
    "    return {\n",
    "        **inputs,                 # ä¼ ä¸‹æ¸¸çš„å­—æ®µéƒ½ä¿ç•™\n",
    "        \"context\": ctx,\n",
    "        \"question\": question,\n",
    "        \"summary\": summary\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ee2372d",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_retriever = RunnableLambda(build_inputs)\n",
    "\n",
    "base_chain: Runnable = (\n",
    "    context_retriever |\n",
    "    chat_prompt |\n",
    "    llm |\n",
    "    StrOutputParser()\n",
    ")\n",
    "\n",
    "chatbot = RunnableWithMessageHistory(\n",
    "    base_chain,\n",
    "    history_factory,\n",
    "    input_messages_key=\"input\",      # æœ¬è½®é—®é¢˜å­—æ®µ\n",
    "    history_messages_key=\"history\"   # å¤šè½®æ¶ˆæ¯å­—æ®µ\n",
    ")\n",
    "\n",
    "\n",
    "# â”€â”€ 6. å•è½®è°ƒç”¨æ¥å£ (invokeâ†’æ›´æ–°æ‘˜è¦â†’è£å‰ª) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  # â† CHANGED\n",
    "def ask(session_id: str, user_question: str) -> str:\n",
    "    resp = chatbot.invoke(\n",
    "        {\"input\": user_question, \"session_id\": session_id},\n",
    "        config={\"configurable\": {\"session_id\": session_id}}\n",
    "    )\n",
    "\n",
    "    hist = history_factory(session_id).messages\n",
    "    update_summary(session_id, hist[-2:])   # æ¯è½®éƒ½å†™æ‘˜è¦\n",
    "    trim_messages(session_id)               # çª—å£&è½®æ•°æ§åˆ¶\n",
    "    return resp\n",
    "\n",
    "\n",
    "# â”€â”€ 7. æ‰“å°è¾…åŠ© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def wrap_text(text, width=120):\n",
    "    return textwrap.fill(text, width=width)\n",
    "\n",
    "def print_chat_state(session_id: str):\n",
    "    msgs = history_factory(session_id).messages\n",
    "    print(\"\\n==== æœ€è¿‘çª—å£ä¸­çš„æ¶ˆæ¯ ====\")\n",
    "\n",
    "    for idx in range(0, len(msgs), 2):\n",
    "        q = wrap_text(msgs[idx].content)\n",
    "        a = wrap_text(msgs[idx+1].content) if idx+1 < len(msgs) else \"(pending)\"\n",
    "        turn_no = (len(msgs) - idx) // 2  # å€’åºæ ‡å·ï¼Œæ›´ç›´è§‚\n",
    "        print(f\"\\nâ—‰ Q-{turn_no}: {q}\\nâ— A-{turn_no}: {a}\")\n",
    "\n",
    "    print(\"\\n---- é•¿æœŸæ‘˜è¦ ----\")\n",
    "    print(wrap_text(summary_store.get(session_id, '(empty)')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9129f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ§‘â€ğŸ’¬ What is beam management?\n",
      "ğŸ¤– Beam management refers to the process of controlling and optimizing the transmission and reception of data in a wireless\n",
      "network by directing radio signals towards specific directions or points. In 5G wireless communication, beam management\n",
      "is used to improve the quality and efficiency of data transmission by focusing signals on specific beams or directions,\n",
      "which can help reduce interference and increase the speed and reliability of data transmission.  Beam management is an\n",
      "important aspect of 5G wireless communication as it enables the network to better utilize the available frequency\n",
      "spectrum and improve the overall performance of the network. By directing signals towards specific beams, 5G networks\n",
      "can reduce interference and improve the overall quality of service for users.  The beam management process involves\n",
      "several steps, including beamforming, beam alignment, and beam tracking. Beamforming involves using advanced signal\n",
      "processing techniques to direct radio signals towards specific beams or directions, while beam alignment involves\n",
      "adjusting the orientation of the antennas to ensure that signals are directed towards the intended beams. Beam tracking\n",
      "involves continuously monitoring and adjusting the orientation of the antennas to maintain the focus of the beams on the\n",
      "intended targets.  The reference for this information is taken from the 3GPP 38321-i50 document, specifically the part\n",
      "that mentions \"For non-interleaved VRB-to-PRB mapping for uplink resource allocation type 2 [6, TS 38.214, 38331-i51].\"\n",
      "\n",
      "==== æœ€è¿‘çª—å£ä¸­çš„æ¶ˆæ¯ ====\n",
      "\n",
      "â—‰ Q-2: what is RB\n",
      "â— A-2: In the context of 5G wireless communication, RB stands for Resource Block. It is a unit of frequency spectrum allocation\n",
      "used for transmitting and receiving data in a wireless network.  <Reference> The information is taken from the 3GPP\n",
      "38211-i60 document, specifically the part that mentions \"For non-interleaved VRB-to-PRB mapping for uplink resource\n",
      "allocation type 2 [6, TS 38.214], virtual resource block is mapped to physical resource block.\"\n",
      "\n",
      "â—‰ Q-1: What is beam management?\n",
      "â— A-1: Beam management refers to the process of controlling and optimizing the transmission and reception of data in a wireless\n",
      "network by directing radio signals towards specific directions or points. In 5G wireless communication, beam management\n",
      "is used to improve the quality and efficiency of data transmission by focusing signals on specific beams or directions,\n",
      "which can help reduce interference and increase the speed and reliability of data transmission.  Beam management is an\n",
      "important aspect of 5G wireless communication as it enables the network to better utilize the available frequency\n",
      "spectrum and improve the overall performance of the network. By directing signals towards specific beams, 5G networks\n",
      "can reduce interference and improve the overall quality of service for users.  The beam management process involves\n",
      "several steps, including beamforming, beam alignment, and beam tracking. Beamforming involves using advanced signal\n",
      "processing techniques to direct radio signals towards specific beams or directions, while beam alignment involves\n",
      "adjusting the orientation of the antennas to ensure that signals are directed towards the intended beams. Beam tracking\n",
      "involves continuously monitoring and adjusting the orientation of the antennas to maintain the focus of the beams on the\n",
      "intended targets.  The reference for this information is taken from the 3GPP 38321-i50 document, specifically the part\n",
      "that mentions \"For non-interleaved VRB-to-PRB mapping for uplink resource allocation type 2 [6, TS 38.214, 38331-i51].\"\n",
      "\n",
      "---- é•¿æœŸæ‘˜è¦ ----\n",
      "Beam management is crucial for 5G wireless communication, optimizing data transmission by directing radio signals\n",
      "towards specific beams, reducing interference, and improving speed and reliability. This process involves beamforming,\n",
      "alignment, and tracking, and is essential for efficient spectrum utilization.\n",
      "====================\n",
      "\n",
      "ğŸ§‘â€ğŸ’¬ And why is it important?\n",
      "ğŸ¤– Beam management is important in 5G wireless communication because it helps to improve the efficiency and performance of\n",
      "the network by directing radio signals towards specific beams or directions. This can help reduce interference and\n",
      "increase the speed and reliability of data transmission. By focusing signals on specific beams, 5G networks can better\n",
      "utilize the available frequency spectrum and improve the overall quality of service for users. Additionally, beam\n",
      "management is essential for efficient spectrum utilization and maintaining a high level of network performance.\n",
      "\n",
      "==== æœ€è¿‘çª—å£ä¸­çš„æ¶ˆæ¯ ====\n",
      "\n",
      "â—‰ Q-2: What is beam management?\n",
      "â— A-2: Beam management refers to the process of controlling and optimizing the transmission and reception of data in a wireless\n",
      "network by directing radio signals towards specific directions or points. In 5G wireless communication, beam management\n",
      "is used to improve the quality and efficiency of data transmission by focusing signals on specific beams or directions,\n",
      "which can help reduce interference and increase the speed and reliability of data transmission.  Beam management is an\n",
      "important aspect of 5G wireless communication as it enables the network to better utilize the available frequency\n",
      "spectrum and improve the overall performance of the network. By directing signals towards specific beams, 5G networks\n",
      "can reduce interference and improve the overall quality of service for users.  The beam management process involves\n",
      "several steps, including beamforming, beam alignment, and beam tracking. Beamforming involves using advanced signal\n",
      "processing techniques to direct radio signals towards specific beams or directions, while beam alignment involves\n",
      "adjusting the orientation of the antennas to ensure that signals are directed towards the intended beams. Beam tracking\n",
      "involves continuously monitoring and adjusting the orientation of the antennas to maintain the focus of the beams on the\n",
      "intended targets.  The reference for this information is taken from the 3GPP 38321-i50 document, specifically the part\n",
      "that mentions \"For non-interleaved VRB-to-PRB mapping for uplink resource allocation type 2 [6, TS 38.214, 38331-i51].\"\n",
      "\n",
      "â—‰ Q-1: And why is it important?\n",
      "â— A-1: Beam management is important in 5G wireless communication because it helps to improve the efficiency and performance of\n",
      "the network by directing radio signals towards specific beams or directions. This can help reduce interference and\n",
      "increase the speed and reliability of data transmission. By focusing signals on specific beams, 5G networks can better\n",
      "utilize the available frequency spectrum and improve the overall quality of service for users. Additionally, beam\n",
      "management is essential for efficient spectrum utilization and maintaining a high level of network performance.\n",
      "\n",
      "---- é•¿æœŸæ‘˜è¦ ----\n",
      "Beam management is crucial for 5G wireless communication as it optimizes data transmission by directing radio signals\n",
      "towards specific beams, reducing interference, and improving speed and reliability.\n",
      "====================\n",
      "\n",
      "ğŸ§‘â€ğŸ’¬ Which 3GPP spec defines it?\n",
      "[INFO] session user_42 reaches 4 turns, resettingâ€¦\n",
      "ğŸ¤– The 3GPP specification that defines beam management in 5G wireless communication is 38321-i50, specifically the part\n",
      "that mentions \"For non-interleaved VRB-to-PRB mapping for uplink resource allocation type 2 [6, TS 38.214, 38331-i51].\"\n",
      "\n",
      "==== æœ€è¿‘çª—å£ä¸­çš„æ¶ˆæ¯ ====\n",
      "\n",
      "---- é•¿æœŸæ‘˜è¦ ----\n",
      "\n",
      "====================\n",
      "\n",
      "ğŸ§‘â€ğŸ’¬ what is ofdma\n",
      "ğŸ¤– OFDMA, or Orthogonal Frequency Division Multiple Access, is a wireless communication technology that allows multiple\n",
      "users to share the same frequency band simultaneously. It does this by dividing the available frequency spectrum into\n",
      "smaller, non-overlapping subchannels or subcarriers, and assigning each user their own set of subchannels to transmit\n",
      "on. This helps to reduce interference between users and improve overall network performance.  <Reference> This\n",
      "information can be found in the document \"Digital Communication Systems\" located at ../documents/Digital-Communication-\n",
      "Systems.pdf, specifically on pages 587 and 588.\n",
      "\n",
      "==== æœ€è¿‘çª—å£ä¸­çš„æ¶ˆæ¯ ====\n",
      "\n",
      "â—‰ Q-1: what is ofdma\n",
      "â— A-1: OFDMA, or Orthogonal Frequency Division Multiple Access, is a wireless communication technology that allows multiple\n",
      "users to share the same frequency band simultaneously. It does this by dividing the available frequency spectrum into\n",
      "smaller, non-overlapping subchannels or subcarriers, and assigning each user their own set of subchannels to transmit\n",
      "on. This helps to reduce interference between users and improve overall network performance.  <Reference> This\n",
      "information can be found in the document \"Digital Communication Systems\" located at ../documents/Digital-Communication-\n",
      "Systems.pdf, specifically on pages 587 and 588.\n",
      "\n",
      "---- é•¿æœŸæ‘˜è¦ ----\n",
      "OFDMA is a wireless communication technology that divides the frequency spectrum into smaller subchannels, allowing for\n",
      "better network performance and reduced interference.\n",
      "====================\n",
      "\n",
      "ğŸ§‘â€ğŸ’¬ what is RB\n",
      "ğŸ¤– RB stands for Resource Block. In the context of OFDMA, it refers to a group of subcarriers that are allocated to a\n",
      "specific user or task within the frequency spectrum. Each Resource Block is divided into smaller units called Resource\n",
      "Elements, which are further divided into Resource Elements Groups. This division allows for better network performance\n",
      "and reduced interference, as it enables multiple users to share the same frequency band more efficiently.\n",
      "\n",
      "==== æœ€è¿‘çª—å£ä¸­çš„æ¶ˆæ¯ ====\n",
      "\n",
      "â—‰ Q-2: what is ofdma\n",
      "â— A-2: OFDMA, or Orthogonal Frequency Division Multiple Access, is a wireless communication technology that allows multiple\n",
      "users to share the same frequency band simultaneously. It does this by dividing the available frequency spectrum into\n",
      "smaller, non-overlapping subchannels or subcarriers, and assigning each user their own set of subchannels to transmit\n",
      "on. This helps to reduce interference between users and improve overall network performance.  <Reference> This\n",
      "information can be found in the document \"Digital Communication Systems\" located at ../documents/Digital-Communication-\n",
      "Systems.pdf, specifically on pages 587 and 588.\n",
      "\n",
      "â—‰ Q-1: what is RB\n",
      "â— A-1: RB stands for Resource Block. In the context of OFDMA, it refers to a group of subcarriers that are allocated to a\n",
      "specific user or task within the frequency spectrum. Each Resource Block is divided into smaller units called Resource\n",
      "Elements, which are further divided into Resource Elements Groups. This division allows for better network performance\n",
      "and reduced interference, as it enables multiple users to share the same frequency band more efficiently.\n",
      "\n",
      "---- é•¿æœŸæ‘˜è¦ ----\n",
      "OFDMA is a wireless communication technology that divides the frequency spectrum into smaller subchannels for better\n",
      "network performance and reduced interference. Users prefer RB (Resource Block) which groups subcarriers allocated to\n",
      "specific users or tasks within the frequency spectrum, further divided into smaller units called Resource Elements and\n",
      "Resource Elements Groups for efficient sharing among multiple users.\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "# ç¬¬ 1 è½®\n",
    "sid = \"user_42\"\n",
    "\n",
    "for q in [\n",
    "\"What is beam management?\",\n",
    "\"And why is it important?\",\n",
    "\"Which 3GPP spec defines it?\",\n",
    "\"what is ofdma\",\n",
    "\"what is RB\"\n",
    "]:\n",
    "    print(f\"\\nğŸ§‘â€ğŸ’¬ {q}\")\n",
    "    print(f\"ğŸ¤– {wrap_text(ask(sid, q))}\")\n",
    "\n",
    "    print_chat_state(sid)\n",
    "    print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98915541",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2413bcef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
