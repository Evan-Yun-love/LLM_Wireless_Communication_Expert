{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f024414",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docs_preprocess import DocumentProcessor\n",
    "from VecStore import VectorStore\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfca5bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lyus4/anaconda3/envs/rag_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Optional, Any\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "import torch\n",
    "from langchain_core.language_models.llms import LLM\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "class DeepSeekLLM(LLM):\n",
    "    model: Any\n",
    "    tokenizer: Any\n",
    "\n",
    "    # ==== 通用生成超参 ====\n",
    "    max_new_tokens: int = 512\n",
    "    temperature: float  = 0.7\n",
    "    do_sample: bool     = True\n",
    "    top_p: float        = 0.9\n",
    "    top_k: int          = 50\n",
    "\n",
    "    # 让 IDE 能补全；LangChain 会用\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"deepseek_hf\"\n",
    "\n",
    "    # --- 自动补 pad_token_id，避免警告 ---\n",
    "    def __post_init__(self):\n",
    "        if self.tokenizer.pad_token_id is None:\n",
    "            self.tokenizer.pad_token_id = self.tokenizer.eos_token_id\n",
    "        if getattr(self.model.config, \"pad_token_id\", None) is None:\n",
    "            self.model.config.pad_token_id = self.tokenizer.pad_token_id\n",
    "\n",
    "    # -------------------------------------------------------------\n",
    "    def _call(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        stop: Optional[List[str]] = None,\n",
    "        **kwargs,\n",
    "    ) -> str:\n",
    "\n",
    "        # 1) prompt → input_ids\n",
    "        messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "        input_ids = self.tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            add_generation_prompt=True,\n",
    "            return_tensors=\"pt\",\n",
    "        ).to(self.model.device)\n",
    "\n",
    "        attention_mask = (input_ids != self.tokenizer.pad_token_id).long()\n",
    "\n",
    "        # 2) 组装超参（kwargs > 实例字段）\n",
    "        gen_kwargs = dict(\n",
    "            max_new_tokens = kwargs.get(\"max_new_tokens\", self.max_new_tokens),\n",
    "            do_sample      = kwargs.get(\"do_sample\",      self.do_sample),\n",
    "            temperature    = kwargs.get(\"temperature\",    self.temperature),\n",
    "            top_p          = kwargs.get(\"top_p\",          self.top_p),\n",
    "            top_k          = kwargs.get(\"top_k\",          self.top_k),\n",
    "            pad_token_id   = self.tokenizer.pad_token_id,\n",
    "            attention_mask = attention_mask,\n",
    "        )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model.generate(input_ids, **gen_kwargs)\n",
    "\n",
    "        text = self.tokenizer.decode(\n",
    "            outputs[0][input_ids.shape[1]:],\n",
    "            skip_special_tokens=True,\n",
    "        )\n",
    "\n",
    "        # 3) stop words 手动截断\n",
    "        if stop:\n",
    "            for s in stop:\n",
    "                if s in text:\n",
    "                    text = text.split(s)[0]\n",
    "\n",
    "        return text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d399e087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-14 18:07:18,421] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lyus4/anaconda3/envs/rag_env/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "/home/lyus4/anaconda3/envs/rag_env/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.44s/it]\n",
      "We've detected an older driver with an RTX 4000 series GPU. These drivers have issues with P2P. This can affect the multi-gpu inference when using accelerate device_map.Please make sure to update your driver to the latest version which resolves this.\n"
     ]
    }
   ],
   "source": [
    "model_dir = \"/home/lyus4/yuheng/All_in_LLM/deepseek-llm-7b-chat\"\n",
    "tok   = AutoTokenizer.from_pretrained(model_dir, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_dir,\n",
    "                                             trust_remote_code=True,\n",
    "                                             torch_dtype=\"auto\",\n",
    "                                             device_map=\"auto\",\n",
    "                                            )\n",
    "\n",
    "llm = DeepSeekLLM(model=model, tokenizer=tok, max_new_tokens=512, temperature=0.2, do_sample = True, top_p = 0.95, top_k = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48798d37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bae25f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 路径配置\n",
    "MODEL_PATH =  \"/home/lyus4/yuheng/All_in_LLM/all-MiniLM-L6-v2\"\n",
    "INDEX_PATH = Path(\"../vector_store/faiss_ivfflat_100\")  # 无需加 .index 后缀\n",
    "VECTORS_PATH = Path(\"../index/vectors.npy\")\n",
    "DOC_JSON_PATH = Path(\"output_chunks.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88c2281f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 初始化 VectorStore -> ../vector_store/faiss_ivfflat_100\n",
      "[INFO] 索引加载成功: ../vector_store/faiss_ivfflat_100\n",
      "[INFO] 类型: IndexIVFFlat, 维度: 384, 数量: 18343\n",
      "[INFO] 加载文档 18343 条\n",
      "\n",
      "[INFO] VectorStore 状态描述：\n",
      "- 文档数: 18343\n",
      "- 向量数: 0\n",
      "- 索引类型: IndexIVFFlat\n",
      "- 向量维度: 384\n",
      "- 向量总数: 18343\n"
     ]
    }
   ],
   "source": [
    "vs = VectorStore(model_path=MODEL_PATH, db_path=INDEX_PATH)\n",
    "vs.load_documents_and_metadata(json_path=DOC_JSON_PATH)\n",
    "vs.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b80284a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── 依赖 ─────────────────────────────────────────────────────────────\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import (\n",
    "    Runnable, RunnableLambda, RunnableWithMessageHistory\n",
    ")\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "import textwrap\n",
    "from utils import format_context_grouped, expand_acronyms\n",
    "\n",
    "# 一个极简摘要 Prompt\n",
    "summary_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \n",
    "     \"You are a note-taking assistant.\\n\"\n",
    "     \"Rewrite the following conversation so far into 1-2 concise sentences, \"\n",
    "     \"focusing only on facts or user preferences we should remember.\\n\\n\"\n",
    "     \"{conversation}\")\n",
    "])\n",
    "summary_chain = summary_prompt | llm | StrOutputParser()\n",
    "\n",
    "history_store      = {}   # 原有\n",
    "summary_store      = {}   # 新增：session_id -> str\n",
    "\n",
    "MAX_HISTORY_EVENTS = 4        # 窗口内原始消息 <= 6 条\n",
    "MAX_TURNS_PER_SESSION = 4    # 方案 A：30 个 Q/A 后重置\n",
    "MAX_SUMMARY_CHARS = 100       # 方案 B：摘要长度阈值（字符）\n",
    "RESET_PRESERVE_SUMMARY  = False\n",
    "\n",
    "# 你的llm和vs初始化略\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3224af55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def history_factory(session_id: str) -> InMemoryChatMessageHistory:\n",
    "    if session_id not in history_store:\n",
    "        history_store[session_id] = InMemoryChatMessageHistory()\n",
    "    return history_store[session_id]\n",
    "\n",
    "# ---------- A. 每轮都更新长期摘要 ---------------------------------  # ← CHANGED\n",
    "def update_summary(session_id: str, new_messages):\n",
    "    \"\"\"把旧摘要 + 本轮内容 → 新摘要；若过长再重压缩。\"\"\"\n",
    "    prev = summary_store.get(session_id, \"\")\n",
    "    delta = \"\\n\".join(m.content for m in new_messages).strip()\n",
    "    conversation = f\"{prev}\\n{delta}\".strip() if prev else delta\n",
    "\n",
    "    try:\n",
    "        summary = summary_chain.invoke({\"conversation\": conversation})\n",
    "    except Exception:\n",
    "        return  # 失败保持旧摘要\n",
    "\n",
    "    # ---- 若摘要太长，再压成一句话 ----\n",
    "    if len(summary) > MAX_SUMMARY_CHARS:\n",
    "        try:\n",
    "            summary = summary_chain.invoke({\n",
    "                \"conversation\": summary,\n",
    "                # 也可以让 prompt 变成“再浓缩成一句”\n",
    "            })\n",
    "        except Exception:\n",
    "            pass    # 兜底仍用超长版本\n",
    "\n",
    "    summary_store[session_id] = summary\n",
    "\n",
    "\n",
    "# ---------- B. 仅裁剪短期窗口 ------------------------------------  # ← CHANGED\n",
    "def _msg_role(msg) -> str:\n",
    "    \"\"\"return 'human' / 'ai' / 'system'... 兼容 .role 和 .type\"\"\"\n",
    "    return getattr(msg, \"role\", getattr(msg, \"type\", \"\")).lower()\n",
    "\n",
    "turn_counter: dict[str, int] = {}\n",
    "\n",
    "def trim_messages(session_id: str):\n",
    "    hist_obj = history_factory(session_id)\n",
    "    msgs     = hist_obj.messages\n",
    "\n",
    "    # ------- 1. 回合计数（在裁剪之前） -------\n",
    "    turns = turn_counter.get(session_id, 0)\n",
    "    # 当且仅当“用户 + AI”各到位才算一轮\n",
    "    if len(msgs) >= 2 and _msg_role(msgs[-1]) in (\"ai\", \"assistant\"):\n",
    "        turns += 1\n",
    "        turn_counter[session_id] = turns\n",
    "\n",
    "    if turns >= MAX_TURNS_PER_SESSION:\n",
    "        print(f\"[INFO] session {session_id} reaches {turns} turns, resetting…\")\n",
    "        history_store[session_id] = InMemoryChatMessageHistory()\n",
    "        turn_counter[session_id]  = 0\n",
    "        if not RESET_PRESERVE_SUMMARY:\n",
    "            summary_store[session_id] = \"\"\n",
    "        return                      # 直接返回，下面裁剪已无意义\n",
    "\n",
    "    # ------- 2. 窗口裁剪（保证成对） -------\n",
    "    if len(msgs) > MAX_HISTORY_EVENTS:\n",
    "        start = len(msgs) - MAX_HISTORY_EVENTS\n",
    "        if _msg_role(msgs[start]) not in (\"human\", \"user\"):\n",
    "            start += 1\n",
    "        msgs[:] = msgs[start:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "930c3a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_test = \"\"\"\n",
    "<Role>\n",
    "You are a 5G wireless communication expert.\n",
    "\n",
    "<Goal>\n",
    "Answer the question using the information in the context below.\n",
    "If the context is insufficient, reply exactly: **\"I don't know\"**.\n",
    "\n",
    "<Memory>\n",
    "{summary}\n",
    "\n",
    "<Context>\n",
    "{context}\n",
    "\n",
    "<Question>\n",
    "{question}\n",
    "\n",
    "<Instructions>\n",
    "1. Explain simply and clearly, as if to a non-expert.  \n",
    "2. Give the reference.\n",
    "\n",
    "<Answer>\n",
    "\"\"\"\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template_test),\n",
    "    MessagesPlaceholder(\"history\"),\n",
    "    (\"user\", \"<Question>\\n{question}\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17b26620",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_inputs(inputs: dict):\n",
    "    question       = inputs[\"input\"]\n",
    "    session_id     = inputs[\"session_id\"]     # 👉 ① 把 session_id 一并传进来\n",
    "    history_msgs   = inputs.get(\"history\", [])\n",
    "\n",
    "    # —— A. 检索 query：历史 Human + 当前问题 ——\n",
    "    hist_text = \"\\n\".join(\n",
    "        m.content for m in history_msgs        # 最近几条\n",
    "        if (getattr(m, \"type\", getattr(m, \"role\", \"\")).lower()\n",
    "            in (\"human\", \"user\"))\n",
    "    )\n",
    "    combined       = f\"{hist_text}\\n{question}\" if hist_text else question\n",
    "    expanded_query = expand_acronyms(combined)\n",
    "\n",
    "    # —— B. VS 检索上下文 ——\n",
    "    top_k_results  = vs.search(expanded_query, k=3, score_mode=\"reciprocal\")\n",
    "    ctx            = format_context_grouped(top_k_results,\n",
    "                                            with_metadata=True,\n",
    "                                            with_score=True)\n",
    "\n",
    "    # —— C. 注入摘要 —— \n",
    "    summary        = summary_store.get(session_id, \"\")   # ← 旧记忆\n",
    "    return {\n",
    "        **inputs,                 # 传下游的字段都保留\n",
    "        \"context\": ctx,\n",
    "        \"question\": question,\n",
    "        \"summary\": summary\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ee2372d",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_retriever = RunnableLambda(build_inputs)\n",
    "\n",
    "base_chain: Runnable = (\n",
    "    context_retriever |\n",
    "    chat_prompt |\n",
    "    llm |\n",
    "    StrOutputParser()\n",
    ")\n",
    "\n",
    "chatbot = RunnableWithMessageHistory(\n",
    "    base_chain,\n",
    "    history_factory,\n",
    "    input_messages_key=\"input\",      # 本轮问题字段\n",
    "    history_messages_key=\"history\"   # 多轮消息字段\n",
    ")\n",
    "\n",
    "\n",
    "# ── 6. 单轮调用接口 (invoke→更新摘要→裁剪) ─────────────────────────  # ← CHANGED\n",
    "def ask(session_id: str, user_question: str) -> str:\n",
    "    resp = chatbot.invoke(\n",
    "        {\"input\": user_question, \"session_id\": session_id},\n",
    "        config={\"configurable\": {\"session_id\": session_id}}\n",
    "    )\n",
    "\n",
    "    hist = history_factory(session_id).messages\n",
    "    update_summary(session_id, hist[-2:])   # 每轮都写摘要\n",
    "    trim_messages(session_id)               # 窗口&轮数控制\n",
    "    return resp\n",
    "\n",
    "\n",
    "# ── 7. 打印辅助 ───────────────────────────────────────────────────\n",
    "def wrap_text(text, width=120):\n",
    "    return textwrap.fill(text, width=width)\n",
    "\n",
    "def print_chat_state(session_id: str):\n",
    "    msgs = history_factory(session_id).messages\n",
    "    print(\"\\n==== 最近窗口中的消息 ====\")\n",
    "\n",
    "    for idx in range(0, len(msgs), 2):\n",
    "        q = wrap_text(msgs[idx].content)\n",
    "        a = wrap_text(msgs[idx+1].content) if idx+1 < len(msgs) else \"(pending)\"\n",
    "        turn_no = (len(msgs) - idx) // 2  # 倒序标号，更直观\n",
    "        print(f\"\\n◉ Q-{turn_no}: {q}\\n◎ A-{turn_no}: {a}\")\n",
    "\n",
    "    print(\"\\n---- 长期摘要 ----\")\n",
    "    print(wrap_text(summary_store.get(session_id, '(empty)')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9129f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧑‍💬 What is beam management?\n",
      "🤖 Beam management refers to the process of controlling and optimizing the transmission and reception of data in a wireless\n",
      "network by directing radio signals towards specific directions or points. In 5G wireless communication, beam management\n",
      "is used to improve the quality and efficiency of data transmission by focusing signals on specific beams or directions,\n",
      "which can help reduce interference and increase the speed and reliability of data transmission.  Beam management is an\n",
      "important aspect of 5G wireless communication as it enables the network to better utilize the available frequency\n",
      "spectrum and improve the overall performance of the network. By directing signals towards specific beams, 5G networks\n",
      "can reduce interference and improve the overall quality of service for users.  The beam management process involves\n",
      "several steps, including beamforming, beam alignment, and beam tracking. Beamforming involves using advanced signal\n",
      "processing techniques to direct radio signals towards specific beams or directions, while beam alignment involves\n",
      "adjusting the orientation of the antennas to ensure that signals are directed towards the intended beams. Beam tracking\n",
      "involves continuously monitoring and adjusting the orientation of the antennas to maintain the focus of the beams on the\n",
      "intended targets.  The reference for this information is taken from the 3GPP 38321-i50 document, specifically the part\n",
      "that mentions \"For non-interleaved VRB-to-PRB mapping for uplink resource allocation type 2 [6, TS 38.214, 38331-i51].\"\n",
      "\n",
      "==== 最近窗口中的消息 ====\n",
      "\n",
      "◉ Q-2: what is RB\n",
      "◎ A-2: In the context of 5G wireless communication, RB stands for Resource Block. It is a unit of frequency spectrum allocation\n",
      "used for transmitting and receiving data in a wireless network.  <Reference> The information is taken from the 3GPP\n",
      "38211-i60 document, specifically the part that mentions \"For non-interleaved VRB-to-PRB mapping for uplink resource\n",
      "allocation type 2 [6, TS 38.214], virtual resource block is mapped to physical resource block.\"\n",
      "\n",
      "◉ Q-1: What is beam management?\n",
      "◎ A-1: Beam management refers to the process of controlling and optimizing the transmission and reception of data in a wireless\n",
      "network by directing radio signals towards specific directions or points. In 5G wireless communication, beam management\n",
      "is used to improve the quality and efficiency of data transmission by focusing signals on specific beams or directions,\n",
      "which can help reduce interference and increase the speed and reliability of data transmission.  Beam management is an\n",
      "important aspect of 5G wireless communication as it enables the network to better utilize the available frequency\n",
      "spectrum and improve the overall performance of the network. By directing signals towards specific beams, 5G networks\n",
      "can reduce interference and improve the overall quality of service for users.  The beam management process involves\n",
      "several steps, including beamforming, beam alignment, and beam tracking. Beamforming involves using advanced signal\n",
      "processing techniques to direct radio signals towards specific beams or directions, while beam alignment involves\n",
      "adjusting the orientation of the antennas to ensure that signals are directed towards the intended beams. Beam tracking\n",
      "involves continuously monitoring and adjusting the orientation of the antennas to maintain the focus of the beams on the\n",
      "intended targets.  The reference for this information is taken from the 3GPP 38321-i50 document, specifically the part\n",
      "that mentions \"For non-interleaved VRB-to-PRB mapping for uplink resource allocation type 2 [6, TS 38.214, 38331-i51].\"\n",
      "\n",
      "---- 长期摘要 ----\n",
      "Beam management is crucial for 5G wireless communication, optimizing data transmission by directing radio signals\n",
      "towards specific beams, reducing interference, and improving speed and reliability. This process involves beamforming,\n",
      "alignment, and tracking, and is essential for efficient spectrum utilization.\n",
      "====================\n",
      "\n",
      "🧑‍💬 And why is it important?\n",
      "🤖 Beam management is important in 5G wireless communication because it helps to improve the efficiency and performance of\n",
      "the network by directing radio signals towards specific beams or directions. This can help reduce interference and\n",
      "increase the speed and reliability of data transmission. By focusing signals on specific beams, 5G networks can better\n",
      "utilize the available frequency spectrum and improve the overall quality of service for users. Additionally, beam\n",
      "management is essential for efficient spectrum utilization and maintaining a high level of network performance.\n",
      "\n",
      "==== 最近窗口中的消息 ====\n",
      "\n",
      "◉ Q-2: What is beam management?\n",
      "◎ A-2: Beam management refers to the process of controlling and optimizing the transmission and reception of data in a wireless\n",
      "network by directing radio signals towards specific directions or points. In 5G wireless communication, beam management\n",
      "is used to improve the quality and efficiency of data transmission by focusing signals on specific beams or directions,\n",
      "which can help reduce interference and increase the speed and reliability of data transmission.  Beam management is an\n",
      "important aspect of 5G wireless communication as it enables the network to better utilize the available frequency\n",
      "spectrum and improve the overall performance of the network. By directing signals towards specific beams, 5G networks\n",
      "can reduce interference and improve the overall quality of service for users.  The beam management process involves\n",
      "several steps, including beamforming, beam alignment, and beam tracking. Beamforming involves using advanced signal\n",
      "processing techniques to direct radio signals towards specific beams or directions, while beam alignment involves\n",
      "adjusting the orientation of the antennas to ensure that signals are directed towards the intended beams. Beam tracking\n",
      "involves continuously monitoring and adjusting the orientation of the antennas to maintain the focus of the beams on the\n",
      "intended targets.  The reference for this information is taken from the 3GPP 38321-i50 document, specifically the part\n",
      "that mentions \"For non-interleaved VRB-to-PRB mapping for uplink resource allocation type 2 [6, TS 38.214, 38331-i51].\"\n",
      "\n",
      "◉ Q-1: And why is it important?\n",
      "◎ A-1: Beam management is important in 5G wireless communication because it helps to improve the efficiency and performance of\n",
      "the network by directing radio signals towards specific beams or directions. This can help reduce interference and\n",
      "increase the speed and reliability of data transmission. By focusing signals on specific beams, 5G networks can better\n",
      "utilize the available frequency spectrum and improve the overall quality of service for users. Additionally, beam\n",
      "management is essential for efficient spectrum utilization and maintaining a high level of network performance.\n",
      "\n",
      "---- 长期摘要 ----\n",
      "Beam management is crucial for 5G wireless communication as it optimizes data transmission by directing radio signals\n",
      "towards specific beams, reducing interference, and improving speed and reliability.\n",
      "====================\n",
      "\n",
      "🧑‍💬 Which 3GPP spec defines it?\n",
      "[INFO] session user_42 reaches 4 turns, resetting…\n",
      "🤖 The 3GPP specification that defines beam management in 5G wireless communication is 38321-i50, specifically the part\n",
      "that mentions \"For non-interleaved VRB-to-PRB mapping for uplink resource allocation type 2 [6, TS 38.214, 38331-i51].\"\n",
      "\n",
      "==== 最近窗口中的消息 ====\n",
      "\n",
      "---- 长期摘要 ----\n",
      "\n",
      "====================\n",
      "\n",
      "🧑‍💬 what is ofdma\n",
      "🤖 OFDMA, or Orthogonal Frequency Division Multiple Access, is a wireless communication technology that allows multiple\n",
      "users to share the same frequency band simultaneously. It does this by dividing the available frequency spectrum into\n",
      "smaller, non-overlapping subchannels or subcarriers, and assigning each user their own set of subchannels to transmit\n",
      "on. This helps to reduce interference between users and improve overall network performance.  <Reference> This\n",
      "information can be found in the document \"Digital Communication Systems\" located at ../documents/Digital-Communication-\n",
      "Systems.pdf, specifically on pages 587 and 588.\n",
      "\n",
      "==== 最近窗口中的消息 ====\n",
      "\n",
      "◉ Q-1: what is ofdma\n",
      "◎ A-1: OFDMA, or Orthogonal Frequency Division Multiple Access, is a wireless communication technology that allows multiple\n",
      "users to share the same frequency band simultaneously. It does this by dividing the available frequency spectrum into\n",
      "smaller, non-overlapping subchannels or subcarriers, and assigning each user their own set of subchannels to transmit\n",
      "on. This helps to reduce interference between users and improve overall network performance.  <Reference> This\n",
      "information can be found in the document \"Digital Communication Systems\" located at ../documents/Digital-Communication-\n",
      "Systems.pdf, specifically on pages 587 and 588.\n",
      "\n",
      "---- 长期摘要 ----\n",
      "OFDMA is a wireless communication technology that divides the frequency spectrum into smaller subchannels, allowing for\n",
      "better network performance and reduced interference.\n",
      "====================\n",
      "\n",
      "🧑‍💬 what is RB\n",
      "🤖 RB stands for Resource Block. In the context of OFDMA, it refers to a group of subcarriers that are allocated to a\n",
      "specific user or task within the frequency spectrum. Each Resource Block is divided into smaller units called Resource\n",
      "Elements, which are further divided into Resource Elements Groups. This division allows for better network performance\n",
      "and reduced interference, as it enables multiple users to share the same frequency band more efficiently.\n",
      "\n",
      "==== 最近窗口中的消息 ====\n",
      "\n",
      "◉ Q-2: what is ofdma\n",
      "◎ A-2: OFDMA, or Orthogonal Frequency Division Multiple Access, is a wireless communication technology that allows multiple\n",
      "users to share the same frequency band simultaneously. It does this by dividing the available frequency spectrum into\n",
      "smaller, non-overlapping subchannels or subcarriers, and assigning each user their own set of subchannels to transmit\n",
      "on. This helps to reduce interference between users and improve overall network performance.  <Reference> This\n",
      "information can be found in the document \"Digital Communication Systems\" located at ../documents/Digital-Communication-\n",
      "Systems.pdf, specifically on pages 587 and 588.\n",
      "\n",
      "◉ Q-1: what is RB\n",
      "◎ A-1: RB stands for Resource Block. In the context of OFDMA, it refers to a group of subcarriers that are allocated to a\n",
      "specific user or task within the frequency spectrum. Each Resource Block is divided into smaller units called Resource\n",
      "Elements, which are further divided into Resource Elements Groups. This division allows for better network performance\n",
      "and reduced interference, as it enables multiple users to share the same frequency band more efficiently.\n",
      "\n",
      "---- 长期摘要 ----\n",
      "OFDMA is a wireless communication technology that divides the frequency spectrum into smaller subchannels for better\n",
      "network performance and reduced interference. Users prefer RB (Resource Block) which groups subcarriers allocated to\n",
      "specific users or tasks within the frequency spectrum, further divided into smaller units called Resource Elements and\n",
      "Resource Elements Groups for efficient sharing among multiple users.\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "# 第 1 轮\n",
    "sid = \"user_42\"\n",
    "\n",
    "for q in [\n",
    "\"What is beam management?\",\n",
    "\"And why is it important?\",\n",
    "\"Which 3GPP spec defines it?\",\n",
    "\"what is ofdma\",\n",
    "\"what is RB\"\n",
    "]:\n",
    "    print(f\"\\n🧑‍💬 {q}\")\n",
    "    print(f\"🤖 {wrap_text(ask(sid, q))}\")\n",
    "\n",
    "    print_chat_state(sid)\n",
    "    print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98915541",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2413bcef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
