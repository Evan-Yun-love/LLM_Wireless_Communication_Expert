# **LLM_Wireless_Communication_Expert**

ğŸ¯**å®ç°åŠŸèƒ½ï¼š**
1. å›ç­”é€šä¿¡é¢†åŸŸçŸ¥è¯†

ğŸš©**å®ç°æ­¥éª¤:**
1. è·å–é€šä¿¡çŸ¥è¯†æ–‡æ¡£ï¼š3GPPåè®®ã€é€šä¿¡ç”µå­ä¹¦
2. æ–‡æ¡£è¯»å–ï¼Œæ•°æ®æ¸…æ´—ï¼ˆç”¨æ­£åˆ™ï¼‰ï¼Œå‘é‡åŒ–
3. æ„å»ºé€šä¿¡RAGçŸ¥è¯†åº“
4. æ ¹æ®é€šä¿¡åœºæ™¯ï¼Œè®¾è®¡æé—®Propmtã€æ¨¡ç‰ˆ
5. è¿›è¡Œå¾®è°ƒï¼Œä½¿å¾—æ¨¡å‹å›ç­”æ›´åƒé€šä¿¡ä¸“å®¶
6. å¢åŠ é€šä¿¡å…¬å¼è®¡ç®—ï¼Œå°†ä¸€äº›å…¬å¼å°è£…ä¸ºå‡½æ•°ï¼Œæ ¹æ®æç¤ºä»¥åŠç»™å®šå‚æ•°è¿›è¡Œè®¡ç®—

## ç³»ç»Ÿæ¡†å›¾
![ç³»ç»Ÿæ¡†å›¾](./LWCEç³»ç»Ÿæ¡†å›¾.png)

# ä¸€ã€æ–‡æ¡£å¤„ç†
## ğŸ“„ æ–‡æ¡£æ™ºèƒ½åˆ†å—å¤„ç†ç®¡é“

è¿™æ˜¯ä¸€ä¸ªç”¨äº**æ‰¹é‡å¤„ç†ã€æ¸…æ´—å’Œåˆ†å—PDF/DOCXæ–‡æ¡£**çš„Pythonç®¡é“ï¼Œå¯ä¸ºå¤§è¯­è¨€æ¨¡å‹RAGæ£€ç´¢ã€çŸ¥è¯†åº“æ„å»ºã€ä¿¡æ¯æ£€ç´¢ç­‰ä»»åŠ¡é«˜æ•ˆå‡†å¤‡æ•°æ®ã€‚

## åŠŸèƒ½äº®ç‚¹

* ğŸ“‚ **é€’å½’ç›®å½•æ‰«æ**ï¼Œè‡ªåŠ¨æŸ¥æ‰¾æ‰€æœ‰PDF/DOCXæ–‡æ¡£
* ğŸ“‘ **æŒ‰é¡µæå–æ–‡æ¡£å†…å®¹**ï¼ˆæ”¯æŒPDFå’ŒWordï¼‰
* ğŸ§¹ **å¤šçº§æ–‡æœ¬æ¸…æ´—**ï¼Œå»é™¤å™ªå£°ã€æ ¼å¼ç»Ÿä¸€
* âœ‚ï¸ **è‡ªå®šä¹‰åˆ†å—**ï¼Œæ”¯æŒå—å¤§å°ä¸é‡å è®¾ç½®
* ğŸ”– **ä¸°å¯Œçš„å…ƒæ•°æ®**ï¼ˆæ–‡æ¡£åã€é¡µç ã€å—åºå·ï¼‰
* ğŸ’¾ **æ”¯æŒåˆ†å—æ•°æ®ä¸å…ƒæ•°æ®çš„ä¿å­˜/åŠ è½½ï¼ˆJSONæ ¼å¼ï¼‰**

## ç¯å¢ƒä¾èµ–

```bash
pip install langchain langchain_community pymupdf docx2txt
```

> éœ€è¦ä¾èµ– `PyMuPDF`ï¼ˆPDFæ”¯æŒï¼‰ã€`docx2txt`ï¼ˆDOCXæ”¯æŒï¼‰

## ç”¨æ³•ç¤ºä¾‹

```python
from document_processor import DocumentProcessor

# 1. åˆå§‹åŒ–å¤„ç†å™¨ï¼ŒæŒ‡å®šæ–‡æ¡£ç›®å½•
proc = DocumentProcessor(docs_path="./docs")

# 2. ä¸€é”®æ‰§è¡Œï¼šåŠ è½½æ–‡æ¡£ -> æ¸…æ´—æ–‡æœ¬ -> åˆ†å—å¤„ç†
proc.run_all()

# 3. ä¿å­˜åˆ†å—ç»“æœä¸å…ƒæ•°æ®
proc.save_chunks_and_metadata("chunks.json")

# --- å¦‚éœ€ä¸‹æ¸¸å¤ç”¨ï¼š
proc.load_chunks_and_metadata("chunks.json")
print(proc.chunks[0])
print(proc.chunk_metadata[0])
```

### ç›®å½•ç»“æ„ç¤ºä¾‹

```
project/
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ æ–‡ä»¶1.pdf
â”‚   â””â”€â”€ æ–‡ä»¶2.docx
â”œâ”€â”€ document_processor.py
â”œâ”€â”€ your_script.py
â””â”€â”€ README.md
```

## å‚æ•°è¯´æ˜

| æ–¹æ³•                         | å‚æ•°å             | å«ä¹‰          | é»˜è®¤å€¼ |
| -------------------------- | --------------- | ----------- | --- |
| `split_documents`          | `chunk_size`    | æ¯ä¸ªæ–‡æœ¬å—çš„ç›®æ ‡å­—ç¬¦æ•° | 800 |
| `split_documents`          | `chunk_overlap` | å—é—´é‡å çš„å­—ç¬¦æ•°    | 160 |
| `save_chunks_and_metadata` | `save_path`     | è¾“å‡ºJSONæ–‡ä»¶è·¯å¾„  | -   |
| `load_chunks_and_metadata` | `load_path`     | åŠ è½½JSONæ–‡ä»¶è·¯å¾„  | -   |

## è¾“å‡ºæ•°æ®æ ¼å¼

ä¿å­˜çš„JSONï¼ˆå¦‚ `chunks.json`ï¼‰å†…å®¹ç¤ºä¾‹ï¼š

```json
[
  {
    "chunk": "æŸä¸ªæ–‡æœ¬å—çš„å†…å®¹â€¦â€¦",
    "metadata": {
      "document": "docs/æ–‡ä»¶1.pdf",
      "page": 3,
      "chunk_idx": 0
    }
  },
  ...
]
```

## æ–‡æœ¬æ¸…æ´—ç»†èŠ‚

* ç»Ÿä¸€æ¢è¡Œã€ç©ºæ ¼ä¸ç‰¹æ®Šå­—ç¬¦
* ç§»é™¤ï¼š

  * å„ç±»3GPP/ç”µä¿¡æ–‡æ¡£å¤´/å°¾ã€ç« èŠ‚å·ã€é¡µç ã€å¸¸è§æ ‡é¢˜
  * URLã€é‚®ç®±ã€ç”µè¯/ä¼ çœŸç­‰è”ç³»æ–¹å¼
  * éASCIIå­—ç¬¦ã€å†—ä½™ç©ºè¡Œç©ºæ ¼ç­‰å™ªå£°å†…å®¹
* æ¸…æ´—é€»è¾‘å¯åœ¨`clean_text()`æ–¹æ³•ä¸­è‡ªå®šä¹‰æ‰©å±•

# äºŒã€å‘é‡åŒ–&æ£€ç´¢
## ğŸ” VectorStore å‘é‡åº“ç®¡ç†ä¸æ£€ç´¢å·¥å…·

`VectorStore` æ˜¯ä¸€ä¸ªæ”¯æŒ**æ–‡æœ¬å‘é‡åŒ–ã€FAISS å‘é‡ç´¢å¼•æ„å»ºä¸é«˜æ•ˆæ£€ç´¢**çš„Pythonå·¥å…·ç±»ï¼Œé€‚ç”¨äºå¤§è§„æ¨¡æ–‡æ¡£ã€çŸ¥è¯†åº“ã€RAGæ£€ç´¢å¢å¼ºç­‰åº”ç”¨åœºæ™¯ã€‚æ”¯æŒå¤šç§ç´¢å¼•ç±»å‹ä¸çµæ´»çš„åµŒå…¥æ¨¡å‹æ¥å…¥ã€‚

## âœ¨ ä¸»è¦åŠŸèƒ½

- ğŸ¤– **è‡ªåŠ¨æ–‡æœ¬å‘é‡åŒ–**ï¼ˆæ”¯æŒHuggingFaceæœ¬åœ°/äº‘æ¨¡å‹ï¼‰
- âš¡ **FAISSå¤šç´¢å¼•ç±»å‹ç®¡ç†**ï¼š`IndexFlatL2`ã€`IndexFlatIP`ã€`IVFFlat`ã€`IVFPQ`
- ğŸ“„ **æ”¯æŒå…ƒæ•°æ®å­˜å‚¨ä¸æ£€ç´¢**ï¼ˆæ¯æ¡æ–‡æœ¬é…åˆè‡ªå®šä¹‰metadataï¼‰
- ğŸ·ï¸ **å‘é‡ä¸ç´¢å¼•æ–‡ä»¶å¯æŒä¹…åŒ–ã€åŠ è½½**
- ğŸ” **ç›¸ä¼¼åº¦æ£€ç´¢ã€åˆ†æ•°æ’åºã€è¿‡æ»¤**
- ğŸš¦ **çµæ´»çš„åˆ†æ•°è½¬æ¢ä¸æ¨¡å¼é€‰æ‹©**

## ğŸ› ï¸ ç¯å¢ƒä¾èµ–

```bash
pip install faiss-cpu numpy langchain
# è‹¥éœ€GPUæ”¯æŒå¯ç”¨ faiss-gpu
# è‹¥éœ€ä¸­æ–‡åµŒå…¥æ¨èç»“åˆ: transformers, sentence-transformers
````

## ğŸš€ ç”¨æ³•ç¤ºä¾‹

### 1. åˆå§‹åŒ–ä¸æ–‡æ¡£/å…ƒæ•°æ®åŠ è½½

```python
from vector_store import VectorStore

embedding_model = "BAAI/bge-base-zh-v1.5"
vector_db = VectorStore(model_path=embedding_model, db_path="faiss.index", embedding_device="cuda")

# åŠ è½½ JSON æ•°æ®ï¼ˆæ ¼å¼è§ä¸‹æ–‡ï¼‰
vector_db.load_documents_and_metadata("chunks.json")
```

### 2. æ„å»ºå‘é‡ç´¢å¼•

```python
vector_db.build_from_documents(
    documents=vector_db.documents,
    metadata=vector_db.metadata,
    index_type="flatl2"   # å¯é€‰ flatl2, flatip, ivfflat, ivfpq
)
vector_db.persist()  # æŒä¹…åŒ–ç´¢å¼•æ–‡ä»¶
```

### 3. æ£€ç´¢

```python
query = "ä¸­å›½çš„5Gæ ‡å‡†æœ‰å“ªäº›å…³é”®å†…å®¹ï¼Ÿ"
results = vector_db.search(query, k=3)
for chunk, score, meta in results:
    print(f"å¾—åˆ†: {score:.4f} | æ¥æº: {meta['document']} ç¬¬{meta['page']}é¡µ")
    print(chunk[:100])
```

### 4. åŠ è½½/ä¿å­˜å‘é‡ä¸ç´¢å¼•

```python
vector_db.save_vectors("vectors.npy")
vector_db.load_vectors("vectors.npy")
vector_db.load_vector("faiss.index")
```

### 5. æè¿°å½“å‰å‘é‡åº“çŠ¶æ€

```python
vector_db.describe()
```

## ğŸ“ æ•°æ®æ ¼å¼è¯´æ˜

* è¾“å…¥JSONéœ€ä¸ºå¦‚ä¸‹ç»“æ„ï¼ˆå»ºè®®ä¸å‰è¿°æ–‡æ¡£åˆ†å—å™¨é…åˆï¼‰ï¼š

```json
[
  {
    "chunk": "æ–‡æœ¬å†…å®¹â€¦â€¦",
    "metadata": {
      "document": "docs/xx.pdf",
      "page": 3,
      "chunk_idx": 0
    }
  }
]
```

## âš™ï¸ æ–¹æ³•ä¸å‚æ•°è¯´æ˜

| æ–¹æ³•                            | å‚æ•°                                                            | è¯´æ˜                              |
| ----------------------------- | ------------------------------------------------------------- | ------------------------------- |
| `__init__`                    | model\_path, db\_path, embedding\_device                      | åˆå§‹åŒ–ï¼ŒæŒ‡å®šåµŒå…¥æ¨¡å‹ã€ç´¢å¼•æ–‡ä»¶è·¯å¾„ã€æ¨ç†è®¾å¤‡          |
| `load_documents_and_metadata` | json\_path                                                    | åŠ è½½é¢„å¤„ç†å¥½çš„æ–‡æ¡£åŠå…ƒæ•°æ®ï¼ˆJSONæ–‡ä»¶ï¼‰           |
| `build_from_documents`        | documents, metadata, index\_type, n\_list, pq\_m, batch\_size | æ„å»ºåµŒå…¥å‘é‡å¹¶åˆ›å»ºç´¢å¼•ï¼Œæ”¯æŒæŒ‡å®šç±»å‹å’Œæ‰¹é‡           |
| `rebuild_index_from_vectors`  | index\_type, n\_list, pq\_m                                   | åŸºäºå·²å­˜åœ¨å‘é‡é‡æ–°æ„å»ºæŒ‡å®šç±»å‹ç´¢å¼•               |
| `persist`                     | æ—                                                              | ä¿å­˜å½“å‰FAISSç´¢å¼•å’Œmetaä¿¡æ¯åˆ°ç£ç›˜           |
| `load_vector`                 | db\_path                                                      | åŠ è½½å·²ä¿å­˜çš„FAISSç´¢å¼•æ–‡ä»¶                 |
| `save_vectors`                | path                                                          | ä¿å­˜å‘é‡çŸ©é˜µä¸ºnpyæ–‡ä»¶                    |
| `load_vectors`                | path                                                          | åŠ è½½npyæ ¼å¼çš„å‘é‡çŸ©é˜µ                    |
| `search`                      | query, k, score\_mode, min\_score                             | å¯¹è¾“å…¥queryè¿›è¡Œç›¸ä¼¼åº¦æ£€ç´¢ï¼Œè¿”å›ï¼ˆæ–‡æœ¬ã€åˆ†æ•°ã€å…ƒæ•°æ®ï¼‰åˆ—è¡¨ |
| `describe`                    | æ—                                                              | è¾“å‡ºå½“å‰æ•°æ®åº“/ç´¢å¼•çš„ç®€è¦ä¿¡æ¯                 |

> **å¤‡æ³¨ï¼š**
>
> * `index_type` æ”¯æŒ `flatl2`ï¼ˆæ¬§å¼è·ç¦»ï¼‰ã€`flatip`ï¼ˆå†…ç§¯/ä½™å¼¦ï¼‰ã€`ivfflat`ã€`ivfpq`
> * `score_mode` æ”¯æŒ `reciprocal`ï¼ˆ1/(1+è·ç¦»)ï¼‰ã€`negative`ï¼ˆ-è·ç¦»ï¼‰ã€`linear`ï¼ˆ1-è·ç¦»ï¼‰
> * `metadata` ä¸ºæ¯æ¡æ–‡æœ¬å—çš„è‡ªå®šä¹‰ä¿¡æ¯ï¼ˆå¦‚æ–‡ä»¶ã€é¡µç ã€å—å·ç­‰ï¼‰

## ä¸‰ã€Promptæ„å»º
# ğŸ¤– 5Gå¤šè½®å¯¹è¯RAGæ£€ç´¢æœºå™¨äºº

æœ¬é¡¹ç›®åŸºäº **LangChain 0.1+** æ¡†æ¶ï¼Œå®ç°äº†ä¸€ä¸ªæ”¯æŒ**å¤šè½®å¯¹è¯å†å²ã€æ£€ç´¢å¢å¼ºï¼ˆRAGï¼‰ã€ä¸Šä¸‹æ–‡æ™ºèƒ½æ‹¼æ¥**çš„ 5G é€šä¿¡ä¸“å®¶é—®ç­”æœºå™¨äººã€‚å¯çµæ´»å¯¹æ¥æœ¬åœ°å¤§æ¨¡å‹ã€çŸ¥è¯†å‘é‡åº“ï¼Œæ”¯æŒä¸­è‹±æ–‡æ‹“å±•å’Œå·¥ç¨‹çº§è°ƒç”¨ã€‚

---

## â­ï¸ åŠŸèƒ½äº®ç‚¹

- ğŸ’¬ æ”¯æŒå¤šè½®ä¸Šä¸‹æ–‡é—®ç­”ä¸å†å²è¿½æº¯
- ğŸ” åŠ¨æ€åŸºäºå†å²+æ–°é—®é¢˜è”åˆæ£€ç´¢ç›¸å…³çŸ¥è¯†å—
- ğŸ§  æ”¯æŒå¤šç±»å‹å‘é‡æ•°æ®åº“ï¼ˆå¦‚ FAISS/BGE/GTE/GLMï¼‰
- ğŸ“ Promptå¯çµæ´»æ‰©å±•ï¼ˆä¸­è‹±åŒè¯­ã€ç»“æ„åŒ–è¾“å‡ºï¼‰
- âš™ï¸ ä»£ç åˆ†å±‚æ¸…æ™°ï¼Œæ˜“äºæ‰©å±•é›†æˆ

---

## ğŸš€ ç¯å¢ƒä¾èµ–

```bash
pip install langchain-core langchain faiss-cpu numpy
# è‹¥ç”¨ä¸­æ–‡åµŒå…¥æ¨¡å‹ï¼Œå¯åŠ  transformers sentence-transformers
````

å¦‚éœ€ç”¨æœ¬åœ°/è‡ªå®šä¹‰ LLMã€æˆ–å‘é‡åº“ã€è¯·è‡ªè¡Œå‡†å¤‡å¯¹åº”ä¾èµ–ã€‚

---

## ğŸ“¦ ä»£ç ç»“æ„

* `prompt` ï¼šç³»ç»Ÿè§’è‰²ä¸å›ç­”æ ¼å¼è®¾å®šï¼ˆæ”¯æŒä¸¥æ ¼è‡ªå®šä¹‰ï¼‰
* `build_inputs` ï¼šåŸºäºå†å²æ™ºèƒ½ç”Ÿæˆæ£€ç´¢queryï¼Œæ‹¼è£…ä¸Šä¸‹æ–‡
* `context_retriever` ï¼šå¯æ’æ‹”çš„ä¸Šä¸‹æ–‡è·å–å™¨
* `base_chain` ï¼šRAGä¸»æµç¨‹é“¾ï¼ˆretrieverâ†’promptâ†’llmâ†’è¾“å‡ºè§£æï¼‰
* `history_factory` ï¼šå¤šä¼šè¯å†å²å­˜å‚¨
* `chatbot` ï¼šæ”¯æŒå¤šè½®å†å²çš„å®Œæ•´å¯¹è¯ä½“
* `trim_history` ï¼šå†å²é•¿åº¦æˆªæ–­
* `print_qa_round` ï¼šç¾åŒ–è¾“å‡ºå•è½®é—®ç­”
* `print_chat_history` ï¼šæ‰“å°å®Œæ•´å¯¹è¯å†å²

---

## ğŸ“ Promptæ¨¡æ¿èŒƒä¾‹

```python
template_test = """
<Role>
You are a 5G wireless communication expert.

<Goal>
Answer the question using the information in the context below.
If the context is insufficient, reply exactly: **"I don't know"**.

<Context>
{context}

<Question>
{question}

<Instructions>
1. Explain simply and clearly, as if to a non-expert.  
2. Give the reference.

<Answer>

"""
```

å¦‚éœ€ä¸­è‹±åŒè¯­è¾“å‡ºï¼Œå¯ä»¥å‚è€ƒå¦‚ä¸‹æ–¹å¼ï¼š

```python
<Instructions>
1. Please answer in both English and Chinese, with each version clearly separated.
2. For each language:
    - Explain simply and clearly, as if to a non-expert.
    - Give the reference.
<Answer>
English:
[Your answer in English.]

Chinese:
[ä½ çš„ä¸­æ–‡ç­”æ¡ˆã€‚]
```

---

## ğŸŒŸ ç”¨æ³•ç¤ºä¾‹

```python
# åˆå§‹åŒ–ï¼ˆè¯·æ ¹æ®ä½ å®é™…æƒ…å†µå®ç°llmå’Œvsï¼‰
# from your_llm import llm
# from your_vectordb import vs

session_id = "user_42"

# ç¬¬1è½®
question1 = "What is beam management?"
response1 = chatbot.invoke(
    {"input": question1},
    config={"configurable": {"session_id": session_id}}
)
trim_history(session_id)
print_qa_round(question1, response1)

# ç¬¬2è½®
question2 = "And why is it important?"
response2 = chatbot.invoke(
    {"input": question2},
    config={"configurable": {"session_id": session_id}}
)
trim_history(session_id)
print_qa_round(question2, response2)

# æ‰“å°å†å²é—®ç­”
print_chat_history(session_id)
```

---

## âš™ï¸ æ ¸å¿ƒå‚æ•°è¯´æ˜

| æ–¹æ³•/å˜é‡                        | è¯´æ˜                         |
| ---------------------------- | -------------------------- |
| `chat_prompt`                | èŠå¤©promptæ¨¡æ¿ï¼Œæ”¯æŒå†å²ã€ç»“æ„åŒ–æŒ‡ä»¤      |
| `context_retriever`          | ä¸Šä¸‹æ–‡æ£€ç´¢ä¸æ‹¼è£…å‡½æ•°                 |
| `llm`                        | å¤§è¯­è¨€æ¨¡å‹ï¼ˆå¦‚ChatGLM4ã€DeepSeekç­‰ï¼‰ |
| `vs`                         | å‘é‡æ£€ç´¢åº“ï¼ˆå¦‚faiss+BGEï¼‰          |
| `RunnableWithMessageHistory` | å¤šè½®å¯¹è¯é“¾å°è£…                    |
| `trim_history`               | å¯¹è¯å†å²é•¿åº¦æˆªæ–­ï¼Œé˜²æ­¢æ— é™å¢é•¿            |

---

## ğŸ”§ å¸¸è§è‡ªå®šä¹‰

* æ”¯æŒæ›´å¤æ‚çš„æ£€ç´¢æ¨¡å¼ï¼ˆå¦‚åˆå¹¶å†å²human+aiã€æ£€ç´¢ä¸åŒçŸ¥è¯†åº“ç­‰ï¼‰
* Promptå¯æ‰©å±•ä¸ºå¤šè¯­ç§ã€è¡¨æ ¼ã€Markdownç»“æ„
* å¯¹æ¥æµå¼è¾“å‡ºã€APIæ¥å£æˆ–UIç•Œé¢
* å†å²å­˜å‚¨å¯æ¥å…¥Redisã€æ•°æ®åº“ç­‰æŒä¹…åŒ–
## å››ã€LLMå¾®è°ƒ

## äº”ã€æ€§èƒ½è¯„ä¼°

## é‡åˆ°çš„ä¸€äº›é—®é¢˜ï¼Œä»¥åŠè§£å†³æ–¹æ¡ˆ
1. æµ‹è¯•é›†çš„æ„å»ºï¼Œäººå·¥è¿˜æ˜¯è‡ªåŠ¨ï¼Œè‡ªåŠ¨çš„è¯ï¼Œè°ƒAPIï¼ŒæŠŠchunkå–‚ç»™llmï¼Œè®©å®ƒç”Ÿæˆå¯¹åº”çš„æé—®å’Œå›ç­”
2. ä¸“ä¸šæœ¯è¯­å¤„ç†ï¼Œä¸€äº›ä¹¦é‡Œé¢æ²¡æœ‰ä¸“ä¸šæœ¯è¯­çš„å…¨ç§°è¯´æ˜ï¼Œllmæ²¡æœ‰è¿™æ–¹é¢çŸ¥è¯†ï¼Œä¼šä¹±ç¼–ã€‚è§£å†³æ–¹æ¡ˆå°±æ˜¯æŠŠä¸“ä¸šæœ¯è¯­è¿›è¡Œæ‰©å±•

